{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import os, os.path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "path = 'C:/Users/jumpr_000/Desktop/ransac_obstacle_detection/saved'\n",
    "frames_dir = \"kinect_data/\" #the directory holding the saved depth images in .npy format\n",
    "\n",
    "#camera information based on the Kinect v2 hardware\n",
    "CameraParams = {\n",
    "  \"cx\":254.878,\n",
    "  \"cy\":205.395,\n",
    "  \"fx\":365.456,\n",
    "  \"fy\":365.456,\n",
    "  \"k1\":0.0905474,\n",
    "  \"k2\":-0.26819,\n",
    "  \"k3\":0.0950862,\n",
    "  \"p1\":0.0,\n",
    "  \"p2\":0.0,\n",
    "}\n",
    "\n",
    "# Kinect's physical orientation in the real world.\n",
    "CameraPosition = {\n",
    "    \"x\": 0, # actual position in meters of kinect sensor relative to the viewport's center.\n",
    "    \"y\": 0, # actual position in meters of kinect sensor relative to the viewport's center.\n",
    "    \"z\": 0, # height in meters of actual kinect sensor from the floor.\n",
    "    \"roll\": 0, # angle in degrees of sensor's roll (used for INU input - trig function for this is commented out by default).\n",
    "    \"azimuth\": 0, # sensor's yaw angle in degrees.\n",
    "    \"elevation\": -30, # sensor's pitch angle in degrees.\n",
    "}\n",
    "\n",
    "def depthMatrixToPointCloudPos(z, scale=1000):\n",
    "    \"\"\"\n",
    "    xyz_arr = depthMatrixToPointCloudPos(depth_frame)\n",
    "\n",
    "    Given a depth image, converts each\n",
    "    point to an XYZ coordinate and returns\n",
    "    an array of these points.\n",
    "    The scale is a conversion factor.\n",
    "    Default converts from milimeter\n",
    "    depth data to meters.\n",
    "    \"\"\"\n",
    "    C, R = np.indices(z.shape)\n",
    "\n",
    "    R = np.subtract(R, CameraParams['cx'])\n",
    "    R = np.multiply(R, z)\n",
    "    R = np.divide(R, CameraParams['fx'] * scale)\n",
    "\n",
    "    C = np.subtract(C, CameraParams['cy'])\n",
    "    C = np.multiply(C, z)\n",
    "    C = np.divide(C, CameraParams['fy'] * scale)\n",
    "\n",
    "    return np.column_stack((z.ravel() / scale, R.ravel(), -C.ravel()))\n",
    "\n",
    "def depthToPointCloudPos(x_d, y_d, z, scale=1000):\n",
    "    \"\"\"\n",
    "    x, y, z = (row, col, depth)\n",
    "    \n",
    "    Given a point from a depth image\n",
    "    and its position in the image,\n",
    "    returns the x, y, and z coordinates\n",
    "    relative to the camera location.\n",
    "    The scale is a conversion factor.\n",
    "    Default converts from milimeter\n",
    "    depth data to meters.\n",
    "    \"\"\"\n",
    "    x = (x_d - CameraParams['cx']) * z / CameraParams['fx']\n",
    "    y = (y_d - CameraParams['cy']) * z / CameraParams['fy']\n",
    "\n",
    "    return x / scale, y / scale, z / scale\n",
    "\n",
    "def applyCameraOrientation(pt):\n",
    "    # Kinect Sensor Orientation Compensation\n",
    "    # This runs slowly in Python as it is required to be called within a loop, but it is a more intuitive example than it's vertorized alternative (Purly for example)\n",
    "    # use trig to rotate a vertex around a gimbal.\n",
    "    def rotatePoints(ax1, ax2, deg):\n",
    "        # math to rotate vertexes around a center point on a plane.\n",
    "        hyp = np.sqrt(pt[ax1] ** 2 + pt[ax2] ** 2) # Get the length of the hypotenuse of the real-world coordinate from center of rotation, this is the radius!\n",
    "        d_tan = np.arctan2(pt[ax2], pt[ax1]) # Calculate the vertexes current angle (returns radians that go from -180 to 180)\n",
    "\n",
    "        cur_angle = np.degrees(d_tan) % 360 # Convert radians to degrees and use modulo to adjust range from 0 to 360.\n",
    "        new_angle = np.radians((cur_angle + deg) % 360) # The new angle (in radians) of the vertexes after being rotated by the value of deg.\n",
    "\n",
    "        pt[ax1] = hyp * np.cos(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "        pt[ax2] = hyp * np.sin(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "\n",
    "    #rotatePoints(0, 2, CameraPosition['roll']) #rotate on the Y&Z plane # Disabled because most tripods don't roll. If an Inertial Nav Unit is available this could be used)\n",
    "    rotatePoints(1, 2, CameraPosition['elevation']) #rotate on the X&Z plane\n",
    "    rotatePoints(0, 1, CameraPosition['azimuth']) #rotate on the X&Y plane\n",
    "\n",
    "    # Apply offsets for height and linear position of the sensor (from viewport's center)\n",
    "    pt[:] += np.float_([CameraPosition['x'], CameraPosition['y'], CameraPosition['z']])\n",
    "    return pt\n",
    "\n",
    "def applyCameraMatrixOrientation(pt):\n",
    "    # Kinect Sensor Orientation Compensation\n",
    "    # bacically this is a vectorized version of applyCameraOrientation()\n",
    "    # uses same trig to rotate a vertex around a gimbal.\n",
    "    def rotatePoints(ax1, ax2, deg):\n",
    "        # math to rotate vertexes around a center point on a plane.\n",
    "        hyp = np.sqrt(pt[:, ax1] ** 2 + pt[:, ax2] ** 2) # Get the length of the hypotenuse of the real-world coordinate from center of rotation, this is the radius!\n",
    "        d_tan = np.arctan2(pt[:, ax2], pt[:, ax1]) # Calculate the vertexes current angle (returns radians that go from -180 to 180)\n",
    "\n",
    "        cur_angle = np.degrees(d_tan) % 360 # Convert radians to degrees and use modulo to adjust range from 0 to 360.\n",
    "        new_angle = np.radians((cur_angle + deg) % 360) # The new angle (in radians) of the vertexes after being rotated by the value of deg.\n",
    "\n",
    "        pt[:, ax1] = hyp * np.cos(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "        pt[:, ax2] = hyp * np.sin(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "\n",
    "    #rotatePoints(1, 2, CameraPosition['roll']) #rotate on the Y&Z plane # Disabled because most tripods don't roll. If an Inertial Nav Unit is available this could be used)\n",
    "    rotatePoints(0, 2, CameraPosition['elevation']) #rotate on the X&Z plane\n",
    "    rotatePoints(0, 1, CameraPosition['azimuth']) #rotate on the X&Y\n",
    "\n",
    "    # Apply offsets for height and linear position of the sensor (from viewport's center)\n",
    "    pt[:] += np.float_([CameraPosition['x'], CameraPosition['y'], CameraPosition['z']])\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plane_fit(points):\n",
    "    \"\"\"\n",
    "    p, n = plane_fit(points)\n",
    "\n",
    "    Given an array, points, of shape (d,...)\n",
    "    representing points in d-dimensional space,\n",
    "    fit an d-dimensional plane to the points.\n",
    "    Return a point, p, on the plane (the point-cloud centroid),\n",
    "    and the normal, n.\n",
    "    \"\"\"\n",
    "    from numpy.linalg import svd\n",
    "    points = np.reshape(points, (np.shape(points)[0], -1)) # Collapse trialing dimensions\n",
    "    assert points.shape[0] <= points.shape[1], \"There are only {} points in {} dimensions.\".format(points.shape[1], points.shape[0])\n",
    "    ctr = points.mean(axis=1)\n",
    "    x = points - ctr[:,np.newaxis]\n",
    "    M = np.dot(x, x.T) # Could also use np.cov(x) here.\n",
    "    return ctr, svd(M)[0][:,-1]\n",
    "\n",
    "def get_orientation(xyz_arr, n_iter):\n",
    "    \"\"\"\n",
    "    center, plane, theta = get_orientation(xyz_arr, num_points)\n",
    "\n",
    "    Given an array, points, of shape (d,...)\n",
    "    representing points in d-dimensional space,\n",
    "    fits a plane to the array n_iter times and\n",
    "    returns the average of the planes centers,\n",
    "    norms, and pitch degrees.\n",
    "    \"\"\"\n",
    "    pitch = []\n",
    "    planes = []\n",
    "    centers = []\n",
    "    for _ in range(0, n_iter):\n",
    "        rand_points = []\n",
    "        while len(rand_points) < 10:\n",
    "            index = random.randrange(0,len(xyz_arr))\n",
    "            if not xyz_arr[index].all() == np.zeros(3).all():\n",
    "                rand_points.append(xyz_arr[index])\n",
    "        rand_points = np.array(rand_points).T\n",
    "        ctr, P = plane_fit(rand_points)\n",
    "        r = math.sqrt(P[0]**2 + P[1]**2 + P[2]**2)\n",
    "        theta = math.acos(P[2]/r) * 180 / math.pi\n",
    "        phi = math.atan(P[1]/P[0]) * 180 / math.pi\n",
    "        pitch.append(theta)\n",
    "        planes.append(P)\n",
    "        centers.append(ctr)\n",
    "    return np.mean(centers, axis = 0), np.mean(planes, axis = 0), np.mean(pitch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import os, os.path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def get_obstacles_with_plane(depth_frame, num_planes, num_points, dist_thresh, visualize):\n",
    "    obstacles = np.zeros(depth_frame.shape) #empty image that will store the locations of detected obstacles\n",
    "    img = np.uint8(depth_frame) #some opencv functions require a byte image\n",
    "\n",
    "    xyz_arr = depthMatrixToPointCloudPos(depth_frame) #convert depth data to XYZ coordinates\n",
    "    start_time = time.time()\n",
    "    center, plane, theta = get_orientation(xyz_arr, num_points)\n",
    "    CameraPosition['elevation'] = -theta\n",
    "    center = applyCameraOrientation(center)\n",
    "    plane = applyCameraOrientation(plane)\n",
    "    xyz_arr = applyCameraMatrixOrientation(xyz_arr)\n",
    "    plane_img = np.zeros(len(xyz_arr))\n",
    "    plane_img[xyz_arr[:,2] > dist_thresh - center[2]] = 1\n",
    "    if visualize:\n",
    "        xyz_arr = xyz_arr[xyz_arr[:,2] > dist_thresh - center[2]]\n",
    "        points = pd.DataFrame(xyz_arr, columns=['x', 'y', 'z']) #convert XYZ coordinates to a DataFrame for pyntcloud\n",
    "        cloud = PyntCloud(points)\n",
    "\n",
    "        lines = [\n",
    "            {\n",
    "                # X axis\n",
    "                \"color\": \"red\", \n",
    "                \"vertices\": [[0, 0, 0], [10, 0, 0]]\n",
    "            },\n",
    "            {\n",
    "                # Y axis\n",
    "                \"color\": \"green\",\n",
    "                \"vertices\": [[0, 0, 0], [0, 10, 0]]\n",
    "            },\n",
    "            {\n",
    "                # Z axis\n",
    "                \"color\": \"blue\",\n",
    "                \"vertices\": [[0, 0, 0], [0, 0, 10]]\n",
    "            },\n",
    "            {\n",
    "                #Original norm of the plane\n",
    "                \"color\": \"pink\",\n",
    "                \"vertices\": [center.tolist(), plane.tolist()]\n",
    "            }\n",
    "        ]\n",
    "        cloud.plot(cmap=\"cool\", polylines=lines)\n",
    "\n",
    "    plane_img = np.uint8(np.reshape(plane_img,(424,512)) * 255) #reshape to match depth data and convert to uint8\n",
    "    plane_img = np.uint8((np.ones((424,512)) * 255) - plane_img) #invert img so pixel value corresponds to NOT ground plane\n",
    "    ret, plane_img = cv2.threshold(plane_img,0,255,cv2.THRESH_BINARY) #filter points that are probaly not ground plane\n",
    "    plane_img = cv2.subtract(img, plane_img)\n",
    "    \n",
    "    #noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(plane_img ,cv2.MORPH_OPEN, kernel, iterations = 3) #erosion followed by dilation\n",
    "\n",
    "    color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) #BGR image to draw labels on\n",
    "\n",
    "    #begin contour detection\n",
    "    image, contours, hierarchy = cv2.findContours(opening,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    color = cv2.drawContours(color, contours, -1, (0,255,0), 1)\n",
    "    for cntr in contours:\n",
    "        try:\n",
    "            #calculate diamter of equivalent circle\n",
    "            #this measurement is only used for checking if countours fit our bounds\n",
    "            area = cv2.contourArea(cntr)\n",
    "            equi_diameter = np.sqrt(4*area/np.pi)\n",
    "\n",
    "            #Hardcoded Diameter Range in pixels\n",
    "            LOW_DIAMETER_BOUND = 20\n",
    "            HIGH_DIAMETER_BOUND = 150\n",
    "\n",
    "            HIGH_DISTANCE_BOUND = 4500\n",
    "            #Original tolerances were 20 and 150\n",
    "\n",
    "            if(equi_diameter>LOW_DIAMETER_BOUND and equi_diameter<HIGH_DIAMETER_BOUND):\n",
    "                mask = np.zeros_like(img) #mask will contain the fitted and adjusted ellipse of a single obstacle\n",
    "                ellipse = cv2.fitEllipse(cntr)\n",
    "                x,y,obj_length,obj_height = cv2.boundingRect(cntr)\n",
    "                rect = cv2.minAreaRect(cntr)\n",
    "\n",
    "                equi_diameter = obj_length #bounding rectangle gives a better approximation of diameter\n",
    "\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                mask = cv2.ellipse(mask,ellipse,(255,255,255),-1) #draw the fitted ellipse\n",
    "                rows = mask.shape[0]\n",
    "                cols = mask.shape[1]\n",
    "                M = np.float32([[1,0,0],[0,1,equi_diameter/4]]) #shift mask down to match obstacle, not edge\n",
    "                mask = cv2.warpAffine(mask,M,(cols,rows))\n",
    "                mask = cv2.erode(mask, kernel, iterations=3) #erode the mask to remove background points\n",
    "                img_fg = cv2.bitwise_and(depth_frame,depth_frame,mask = mask) #use the mask to isolate original depth values\n",
    "                img_fg = cv2.medianBlur(img_fg,5) #median blur to further remove noise\n",
    "                obstacles = cv2.add(np.float32(img_fg), np.float32(obstacles)) \n",
    "                \n",
    "                mean_val = np.median(img_fg[img_fg.nonzero()]) #compute the non-zero average of obstacle depth values\n",
    "                min_val, distance_to_object, min_loc, max_loc = cv2.minMaxLoc(img_fg)\n",
    "\n",
    "                moment = cv2.moments(cntr) #get the centroid of the obstacle using its moment\n",
    "                cx = int(moment['m10']/moment['m00'])\n",
    "                cy = int(moment['m01']/moment['m00'])\n",
    "\n",
    "                if mean_val < HIGH_DISTANCE_BOUND: #kinect loses accuracy beyond 4.5m\n",
    "                    coords = depthToPointCloudPos(cx, cy, mean_val) #convert obstacle depth to XYZ coordinate\n",
    "\n",
    "                    mm_diameter = (equi_diameter) * (1.0 / CameraParams['fx']) * mean_val #convert pixel diameter to mm\n",
    "\n",
    "                    #begin visualization\n",
    "                    cv2.drawContours(color,[box],0,(0,0,255),1)\n",
    "                    cv2.rectangle(color,(x,y),(x+obj_length,y+obj_height),(0,255,0),2)\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(color, \"x\" + str(coords[0]), (cx,cy+30), font, 0.4, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color, \"y\" + str(coords[1]), (cx,cy+45), font, 0.4, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color, \"z\" + str(mean_val), (cx,cy+60), font, 0.4, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color,\"diameter = \" + str(mm_diameter), (cx,cy + 15), font, 0.4, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        except:\n",
    "            print (\"Failed to process image\")\n",
    "            print (sys.exc_info()[0])\n",
    "            \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Frame took \" + str(elapsed_time) + \" seconds to process\")\n",
    "\n",
    "    cv2.imshow(\"plane\",plane_img)\n",
    "    cv2.imshow(\"img\",depth_frame)\n",
    "    cv2.imshow(\"final\",color)\n",
    "    cv2.imshow(\"sure_bg\",opening)\n",
    "    cv2.imshow(\"obstacles\",obstacles)\n",
    "    key = cv2.waitKey(delay=1)\n",
    "    return color\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\pythreejs\\traits.py:175: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49842c6643c423aae3d401cfca00915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(3.5865321961577483, 1.4926417230319071, 1.40…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d8e4bc4606437eaf8190b93576b4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.5264860216197518, max=5.264860216197517, step=0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.24300670623779297 seconds to process\n"
     ]
    }
   ],
   "source": [
    "img = np.load('kinect_data/143.npy')\n",
    "output = get_obstacles_with_plane(img, num_planes = 6, \n",
    "                                  num_points = 22, \n",
    "                                  dist_thresh = 0.1, \n",
    "                                  visualize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The Windows bytes API has been deprecated, use Unicode filenames instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinect_data/0.npy\n",
      "Frame took 0.06296348571777344 seconds to process\n",
      "kinect_data/1.npy\n",
      "Frame took 0.05796408653259277 seconds to process\n",
      "kinect_data/10.npy\n",
      "Frame took 0.05596613883972168 seconds to process\n",
      "kinect_data/100.npy\n",
      "Frame took 0.05796647071838379 seconds to process\n",
      "kinect_data/101.npy\n",
      "Frame took 0.06196451187133789 seconds to process\n",
      "kinect_data/102.npy\n",
      "Frame took 0.07295751571655273 seconds to process\n",
      "kinect_data/103.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\jumpr_000\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:109: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.1953258514404297 seconds to process\n",
      "kinect_data/104.npy\n",
      "Frame took 0.052969932556152344 seconds to process\n",
      "kinect_data/105.npy\n",
      "Frame took 0.05396628379821777 seconds to process\n",
      "kinect_data/106.npy\n",
      "Frame took 0.05696749687194824 seconds to process\n",
      "kinect_data/107.npy\n",
      "Frame took 0.05896329879760742 seconds to process\n",
      "kinect_data/108.npy\n",
      "Frame took 0.08395123481750488 seconds to process\n",
      "kinect_data/109.npy\n",
      "Frame took 0.06695914268493652 seconds to process\n",
      "kinect_data/11.npy\n",
      "Frame took 0.05896759033203125 seconds to process\n",
      "kinect_data/110.npy\n",
      "Frame took 0.05496716499328613 seconds to process\n",
      "kinect_data/111.npy\n",
      "Frame took 0.05396890640258789 seconds to process\n",
      "kinect_data/112.npy\n",
      "Frame took 0.07393789291381836 seconds to process\n",
      "kinect_data/113.npy\n",
      "Frame took 0.05696606636047363 seconds to process\n",
      "kinect_data/114.npy\n",
      "Frame took 0.05896353721618652 seconds to process\n",
      "kinect_data/115.npy\n",
      "Frame took 0.05696725845336914 seconds to process\n",
      "kinect_data/116.npy\n",
      "Frame took 0.06096339225769043 seconds to process\n",
      "kinect_data/117.npy\n",
      "Frame took 0.07195544242858887 seconds to process\n",
      "kinect_data/118.npy\n",
      "Frame took 0.06995725631713867 seconds to process\n",
      "kinect_data/119.npy\n",
      "Frame took 0.06897330284118652 seconds to process\n",
      "kinect_data/12.npy\n",
      "Frame took 0.059978485107421875 seconds to process\n",
      "kinect_data/120.npy\n",
      "Frame took 0.06895971298217773 seconds to process\n",
      "kinect_data/121.npy\n",
      "Frame took 0.05396914482116699 seconds to process\n",
      "kinect_data/122.npy\n",
      "Frame took 0.05997872352600098 seconds to process\n",
      "kinect_data/123.npy\n",
      "Frame took 0.05896425247192383 seconds to process\n",
      "kinect_data/124.npy\n",
      "Frame took 0.06997299194335938 seconds to process\n",
      "kinect_data/125.npy\n",
      "Frame took 0.05594611167907715 seconds to process\n",
      "kinect_data/126.npy\n",
      "Frame took 0.059958696365356445 seconds to process\n",
      "kinect_data/127.npy\n",
      "Frame took 0.056960344314575195 seconds to process\n",
      "kinect_data/128.npy\n",
      "Frame took 0.07995009422302246 seconds to process\n",
      "kinect_data/129.npy\n",
      "Frame took 0.06296324729919434 seconds to process\n",
      "kinect_data/13.npy\n",
      "Frame took 0.06895875930786133 seconds to process\n",
      "kinect_data/130.npy\n",
      "Frame took 0.05494999885559082 seconds to process\n",
      "kinect_data/131.npy\n",
      "Frame took 0.06296348571777344 seconds to process\n",
      "kinect_data/132.npy\n",
      "Frame took 0.061963796615600586 seconds to process\n",
      "kinect_data/133.npy\n",
      "Frame took 0.06997847557067871 seconds to process\n",
      "kinect_data/134.npy\n",
      "Frame took 0.06296253204345703 seconds to process\n",
      "kinect_data/135.npy\n",
      "Frame took 0.06496167182922363 seconds to process\n",
      "kinect_data/136.npy\n",
      "Frame took 0.06797671318054199 seconds to process\n",
      "kinect_data/137.npy\n",
      "Frame took 0.0599370002746582 seconds to process\n",
      "kinect_data/138.npy\n",
      "Frame took 0.05996417999267578 seconds to process\n",
      "kinect_data/139.npy\n",
      "Frame took 0.11393404006958008 seconds to process\n",
      "kinect_data/14.npy\n",
      "Frame took 0.06196165084838867 seconds to process\n",
      "kinect_data/140.npy\n",
      "Frame took 0.06098294258117676 seconds to process\n",
      "kinect_data/141.npy\n",
      "Frame took 0.05396914482116699 seconds to process\n",
      "kinect_data/142.npy\n",
      "Frame took 0.059964895248413086 seconds to process\n",
      "kinect_data/143.npy\n",
      "Frame took 0.05795574188232422 seconds to process\n",
      "kinect_data/144.npy\n",
      "Frame took 0.05395078659057617 seconds to process\n",
      "kinect_data/145.npy\n",
      "Frame took 0.06897139549255371 seconds to process\n",
      "kinect_data/146.npy\n",
      "Frame took 0.06195831298828125 seconds to process\n",
      "kinect_data/147.npy\n",
      "Frame took 0.05996346473693848 seconds to process\n",
      "kinect_data/148.npy\n",
      "Frame took 0.052986860275268555 seconds to process\n",
      "kinect_data/149.npy\n",
      "Frame took 0.06896638870239258 seconds to process\n",
      "kinect_data/15.npy\n",
      "Frame took 0.05596590042114258 seconds to process\n",
      "kinect_data/150.npy\n",
      "Frame took 0.058965444564819336 seconds to process\n",
      "kinect_data/151.npy\n",
      "Frame took 0.06596159934997559 seconds to process\n",
      "kinect_data/152.npy\n",
      "Frame took 0.06796026229858398 seconds to process\n",
      "kinect_data/153.npy\n",
      "Frame took 0.06294751167297363 seconds to process\n",
      "kinect_data/154.npy\n",
      "Frame took 0.06495976448059082 seconds to process\n",
      "kinect_data/155.npy\n",
      "Frame took 0.0709526538848877 seconds to process\n",
      "kinect_data/156.npy\n",
      "Frame took 0.06094694137573242 seconds to process\n",
      "kinect_data/157.npy\n",
      "Frame took 0.06896233558654785 seconds to process\n",
      "kinect_data/158.npy\n",
      "Frame took 0.06794357299804688 seconds to process\n",
      "kinect_data/159.npy\n",
      "Frame took 0.06096482276916504 seconds to process\n",
      "kinect_data/16.npy\n",
      "Frame took 0.054967641830444336 seconds to process\n",
      "kinect_data/160.npy\n",
      "Frame took 0.05496788024902344 seconds to process\n",
      "kinect_data/161.npy\n",
      "Frame took 0.06494402885437012 seconds to process\n",
      "kinect_data/162.npy\n",
      "Frame took 0.07194113731384277 seconds to process\n",
      "kinect_data/163.npy\n",
      "Frame took 0.07395648956298828 seconds to process\n",
      "kinect_data/164.npy\n",
      "Frame took 0.058965444564819336 seconds to process\n",
      "kinect_data/165.npy\n",
      "Frame took 0.054967403411865234 seconds to process\n",
      "kinect_data/166.npy\n",
      "Frame took 0.05996370315551758 seconds to process\n",
      "kinect_data/167.npy\n",
      "Frame took 0.06493997573852539 seconds to process\n",
      "kinect_data/168.npy\n",
      "Frame took 0.14991307258605957 seconds to process\n",
      "kinect_data/169.npy\n",
      "Frame took 0.06096458435058594 seconds to process\n",
      "kinect_data/17.npy\n",
      "Frame took 0.060945749282836914 seconds to process\n",
      "kinect_data/170.npy\n",
      "Frame took 0.06396245956420898 seconds to process\n",
      "kinect_data/171.npy\n",
      "Frame took 0.0669398307800293 seconds to process\n",
      "kinect_data/172.npy\n",
      "Frame took 0.06296348571777344 seconds to process\n",
      "kinect_data/173.npy\n",
      "Frame took 0.05998349189758301 seconds to process\n",
      "kinect_data/174.npy\n",
      "Frame took 0.06097698211669922 seconds to process\n",
      "kinect_data/175.npy\n",
      "Frame took 0.06195998191833496 seconds to process\n",
      "kinect_data/176.npy\n",
      "Frame took 0.05295872688293457 seconds to process\n",
      "kinect_data/177.npy\n",
      "Frame took 0.07696819305419922 seconds to process\n",
      "kinect_data/178.npy\n",
      "Frame took 0.059964895248413086 seconds to process\n",
      "kinect_data/179.npy\n",
      "Frame took 0.059983015060424805 seconds to process\n",
      "kinect_data/18.npy\n",
      "Frame took 0.055968523025512695 seconds to process\n",
      "kinect_data/180.npy\n",
      "Frame took 0.05898427963256836 seconds to process\n",
      "kinect_data/181.npy\n",
      "Frame took 0.05898332595825195 seconds to process\n",
      "kinect_data/182.npy\n",
      "Frame took 0.06498026847839355 seconds to process\n",
      "kinect_data/183.npy\n",
      "Frame took 0.06395292282104492 seconds to process\n",
      "kinect_data/184.npy\n",
      "Frame took 0.06395721435546875 seconds to process\n",
      "kinect_data/185.npy\n",
      "Frame took 0.0639500617980957 seconds to process\n",
      "kinect_data/186.npy\n",
      "Frame took 0.06997156143188477 seconds to process\n",
      "kinect_data/187.npy\n",
      "Frame took 0.06395149230957031 seconds to process\n",
      "kinect_data/188.npy\n",
      "Frame took 0.06097579002380371 seconds to process\n",
      "kinect_data/189.npy\n",
      "Frame took 0.058947086334228516 seconds to process\n",
      "kinect_data/19.npy\n",
      "Frame took 0.05596780776977539 seconds to process\n",
      "kinect_data/190.npy\n",
      "Frame took 0.05995631217956543 seconds to process\n",
      "kinect_data/191.npy\n",
      "Frame took 0.07595467567443848 seconds to process\n",
      "kinect_data/192.npy\n",
      "Frame took 0.06196451187133789 seconds to process\n",
      "kinect_data/193.npy\n",
      "Frame took 0.05996441841125488 seconds to process\n",
      "kinect_data/194.npy\n",
      "Frame took 0.07095980644226074 seconds to process\n",
      "kinect_data/195.npy\n",
      "Frame took 0.05997967720031738 seconds to process\n",
      "kinect_data/196.npy\n",
      "Frame took 0.06194591522216797 seconds to process\n",
      "kinect_data/197.npy\n",
      "Frame took 0.07097625732421875 seconds to process\n",
      "kinect_data/198.npy\n",
      "Frame took 0.1669023036956787 seconds to process\n",
      "kinect_data/199.npy\n",
      "Frame took 0.06094050407409668 seconds to process\n",
      "kinect_data/2.npy\n",
      "Frame took 0.05494856834411621 seconds to process\n",
      "kinect_data/20.npy\n",
      "Frame took 0.056982994079589844 seconds to process\n",
      "kinect_data/200.npy\n",
      "Frame took 0.06096386909484863 seconds to process\n",
      "kinect_data/201.npy\n",
      "Frame took 0.05398368835449219 seconds to process\n",
      "kinect_data/202.npy\n",
      "Frame took 0.08195233345031738 seconds to process\n",
      "kinect_data/203.npy\n",
      "Frame took 0.056948184967041016 seconds to process\n",
      "kinect_data/204.npy\n",
      "Frame took 0.06296396255493164 seconds to process\n",
      "kinect_data/205.npy\n",
      "Frame took 0.055966854095458984 seconds to process\n",
      "kinect_data/206.npy\n",
      "Frame took 0.05395078659057617 seconds to process\n",
      "kinect_data/207.npy\n",
      "Frame took 0.055948495864868164 seconds to process\n",
      "kinect_data/208.npy\n",
      "Frame took 0.055963993072509766 seconds to process\n",
      "kinect_data/209.npy\n",
      "Frame took 0.05395030975341797 seconds to process\n",
      "kinect_data/21.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.05698537826538086 seconds to process\n",
      "kinect_data/210.npy\n",
      "Frame took 0.05396890640258789 seconds to process\n",
      "kinect_data/211.npy\n",
      "Frame took 0.06594109535217285 seconds to process\n",
      "kinect_data/212.npy\n",
      "Frame took 0.05497288703918457 seconds to process\n",
      "kinect_data/213.npy\n",
      "Frame took 0.05495285987854004 seconds to process\n",
      "kinect_data/214.npy\n",
      "Frame took 0.054967641830444336 seconds to process\n",
      "kinect_data/215.npy\n",
      "Frame took 0.05596590042114258 seconds to process\n",
      "kinect_data/216.npy\n",
      "Frame took 0.05494880676269531 seconds to process\n",
      "kinect_data/217.npy\n",
      "Frame took 0.053969383239746094 seconds to process\n",
      "kinect_data/218.npy\n",
      "Frame took 0.05696511268615723 seconds to process\n",
      "kinect_data/219.npy\n",
      "Frame took 0.053968191146850586 seconds to process\n",
      "kinect_data/22.npy\n",
      "Frame took 0.06897878646850586 seconds to process\n",
      "kinect_data/220.npy\n",
      "Frame took 0.055966854095458984 seconds to process\n",
      "kinect_data/221.npy\n",
      "Frame took 0.05696511268615723 seconds to process\n",
      "kinect_data/222.npy\n",
      "Frame took 0.06496214866638184 seconds to process\n",
      "kinect_data/223.npy\n",
      "Frame took 0.05396890640258789 seconds to process\n",
      "kinect_data/224.npy\n",
      "Frame took 0.05695080757141113 seconds to process\n",
      "kinect_data/225.npy\n",
      "Frame took 0.05696725845336914 seconds to process\n",
      "kinect_data/226.npy\n",
      "Frame took 0.13592195510864258 seconds to process\n",
      "kinect_data/227.npy\n",
      "Frame took 0.05596637725830078 seconds to process\n",
      "kinect_data/228.npy\n",
      "Frame took 0.05396580696105957 seconds to process\n",
      "kinect_data/229.npy\n",
      "Frame took 0.05497121810913086 seconds to process\n",
      "kinect_data/23.npy\n",
      "Frame took 0.056966304779052734 seconds to process\n",
      "kinect_data/24.npy\n",
      "Frame took 0.06895732879638672 seconds to process\n",
      "kinect_data/25.npy\n",
      "Frame took 0.07695937156677246 seconds to process\n",
      "kinect_data/26.npy\n",
      "Frame took 0.06895327568054199 seconds to process\n",
      "kinect_data/27.npy\n",
      "Frame took 0.06397604942321777 seconds to process\n",
      "kinect_data/28.npy\n",
      "Frame took 0.06397676467895508 seconds to process\n",
      "kinect_data/29.npy\n",
      "Frame took 0.05998349189758301 seconds to process\n",
      "kinect_data/3.npy\n",
      "Frame took 0.05994701385498047 seconds to process\n",
      "kinect_data/30.npy\n",
      "Frame took 0.05996513366699219 seconds to process\n",
      "kinect_data/31.npy\n",
      "Frame took 0.05996346473693848 seconds to process\n",
      "kinect_data/32.npy\n",
      "Frame took 0.06196284294128418 seconds to process\n",
      "kinect_data/33.npy\n",
      "Frame took 0.07095861434936523 seconds to process\n",
      "kinect_data/34.npy\n",
      "Frame took 0.05894637107849121 seconds to process\n",
      "kinect_data/35.npy\n",
      "Frame took 0.06396079063415527 seconds to process\n",
      "kinect_data/36.npy\n",
      "Frame took 0.06897544860839844 seconds to process\n",
      "kinect_data/37.npy\n",
      "Frame took 0.06595993041992188 seconds to process\n",
      "kinect_data/38.npy\n",
      "Frame took 0.07195806503295898 seconds to process\n",
      "kinect_data/39.npy\n",
      "Frame took 0.07297539710998535 seconds to process\n",
      "kinect_data/4.npy\n",
      "Frame took 0.05496788024902344 seconds to process\n",
      "kinect_data/40.npy\n",
      "Frame took 0.05296921730041504 seconds to process\n",
      "kinect_data/41.npy\n",
      "Frame took 0.07994818687438965 seconds to process\n",
      "kinect_data/42.npy\n",
      "Frame took 0.07197237014770508 seconds to process\n",
      "kinect_data/43.npy\n",
      "Frame took 0.05896568298339844 seconds to process\n",
      "kinect_data/44.npy\n",
      "Frame took 0.06596183776855469 seconds to process\n",
      "kinect_data/45.npy\n",
      "Frame took 0.06997799873352051 seconds to process\n",
      "kinect_data/46.npy\n",
      "Frame took 0.06395530700683594 seconds to process\n",
      "kinect_data/47.npy\n",
      "Frame took 0.052967071533203125 seconds to process\n",
      "kinect_data/48.npy\n",
      "Frame took 0.07495498657226562 seconds to process\n",
      "kinect_data/49.npy\n",
      "Frame took 0.17989540100097656 seconds to process\n",
      "kinect_data/5.npy\n",
      "Frame took 0.05696678161621094 seconds to process\n",
      "kinect_data/50.npy\n",
      "Frame took 0.07297563552856445 seconds to process\n",
      "kinect_data/51.npy\n",
      "Frame took 0.05997920036315918 seconds to process\n",
      "kinect_data/52.npy\n",
      "Frame took 0.06096506118774414 seconds to process\n",
      "kinect_data/53.npy\n",
      "Frame took 0.05796647071838379 seconds to process\n",
      "kinect_data/54.npy\n",
      "Frame took 0.07795429229736328 seconds to process\n",
      "kinect_data/55.npy\n",
      "Frame took 0.07696771621704102 seconds to process\n",
      "kinect_data/56.npy\n",
      "Frame took 0.078948974609375 seconds to process\n",
      "kinect_data/57.npy\n",
      "Frame took 0.0749671459197998 seconds to process\n",
      "kinect_data/58.npy\n",
      "Frame took 0.08594608306884766 seconds to process\n",
      "kinect_data/59.npy\n",
      "Frame took 0.06396365165710449 seconds to process\n",
      "kinect_data/6.npy\n",
      "Frame took 0.055966854095458984 seconds to process\n",
      "kinect_data/60.npy\n",
      "Frame took 0.05394768714904785 seconds to process\n",
      "kinect_data/61.npy\n",
      "Frame took 0.08295202255249023 seconds to process\n",
      "kinect_data/62.npy\n",
      "Frame took 0.07195734977722168 seconds to process\n",
      "kinect_data/63.npy\n",
      "Frame took 0.06897759437561035 seconds to process\n",
      "kinect_data/64.npy\n",
      "Frame took 0.05496644973754883 seconds to process\n",
      "kinect_data/65.npy\n",
      "Frame took 0.07695531845092773 seconds to process\n",
      "kinect_data/66.npy\n",
      "Frame took 0.07895398139953613 seconds to process\n",
      "kinect_data/67.npy\n",
      "Frame took 0.08295202255249023 seconds to process\n",
      "kinect_data/68.npy\n",
      "Frame took 0.09095907211303711 seconds to process\n",
      "kinect_data/69.npy\n",
      "Frame took 0.07995343208312988 seconds to process\n",
      "kinect_data/7.npy\n",
      "Frame took 0.05494880676269531 seconds to process\n",
      "kinect_data/70.npy\n",
      "Frame took 0.07393717765808105 seconds to process\n",
      "kinect_data/71.npy\n",
      "Frame took 0.05596613883972168 seconds to process\n",
      "kinect_data/72.npy\n",
      "Frame took 0.07397079467773438 seconds to process\n",
      "kinect_data/73.npy\n",
      "Frame took 0.05897951126098633 seconds to process\n",
      "kinect_data/74.npy\n",
      "Frame took 0.07895374298095703 seconds to process\n",
      "kinect_data/75.npy\n",
      "Frame took 0.05596733093261719 seconds to process\n",
      "kinect_data/76.npy\n",
      "Frame took 0.06995964050292969 seconds to process\n",
      "kinect_data/77.npy\n",
      "Frame took 0.053986310958862305 seconds to process\n",
      "kinect_data/78.npy\n",
      "Frame took 0.05296921730041504 seconds to process\n",
      "kinect_data/79.npy\n",
      "Frame took 0.054967403411865234 seconds to process\n",
      "kinect_data/8.npy\n",
      "Frame took 0.054967403411865234 seconds to process\n",
      "kinect_data/80.npy\n",
      "Frame took 0.07895183563232422 seconds to process\n",
      "kinect_data/81.npy\n",
      "Frame took 0.06895995140075684 seconds to process\n",
      "kinect_data/82.npy\n",
      "Frame took 0.07095861434936523 seconds to process\n",
      "kinect_data/83.npy\n",
      "Frame took 0.05396723747253418 seconds to process\n",
      "kinect_data/84.npy\n",
      "Frame took 0.05596804618835449 seconds to process\n",
      "kinect_data/85.npy\n",
      "Frame took 0.0599818229675293 seconds to process\n",
      "kinect_data/86.npy\n",
      "Frame took 0.07595562934875488 seconds to process\n",
      "kinect_data/87.npy\n",
      "Frame took 0.06796073913574219 seconds to process\n",
      "kinect_data/88.npy\n",
      "Frame took 0.05396747589111328 seconds to process\n",
      "kinect_data/89.npy\n",
      "Frame took 0.07297325134277344 seconds to process\n",
      "kinect_data/9.npy\n",
      "Frame took 0.05696749687194824 seconds to process\n",
      "kinect_data/90.npy\n",
      "Frame took 0.06994009017944336 seconds to process\n",
      "kinect_data/91.npy\n",
      "Frame took 0.07693624496459961 seconds to process\n",
      "kinect_data/92.npy\n",
      "Frame took 0.07695531845092773 seconds to process\n",
      "kinect_data/93.npy\n",
      "Frame took 0.06896018981933594 seconds to process\n",
      "kinect_data/94.npy\n",
      "Frame took 0.06396245956420898 seconds to process\n",
      "kinect_data/95.npy\n",
      "Frame took 0.06497526168823242 seconds to process\n",
      "kinect_data/96.npy\n",
      "Frame took 0.05297684669494629 seconds to process\n",
      "kinect_data/97.npy\n",
      "Frame took 0.056949615478515625 seconds to process\n",
      "kinect_data/98.npy\n",
      "Frame took 0.053968191146850586 seconds to process\n",
      "kinect_data/99.npy\n",
      "Frame took 0.05396842956542969 seconds to process\n"
     ]
    }
   ],
   "source": [
    "frames_dir = 'kinect_data/'\n",
    "directory = os.fsencode(frames_dir)\n",
    "frame_i = 0\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".npy\"):\n",
    "        file_path = frames_dir + filename\n",
    "        print(file_path)\n",
    "        img = np.load(file_path)\n",
    "        try:\n",
    "            output = get_obstacles_with_plane(img, num_planes = 11, \n",
    "                                  num_points = 4, \n",
    "                                  dist_thresh = 0.01, \n",
    "                                  visualize = False)\n",
    "            cv2.imwrite(os.path.join(path ,filename[:-4] + '.png'), output)\n",
    "            frame_i += 1\n",
    "        except:\n",
    "            print(\"Could not find obstacles\")\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
