{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import os, os.path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "path = 'C:/Users/jumpr_000/Desktop/ransac_obstacle_detection/saved'\n",
    "frames_dir = \"kinect_data/\" #the directory holding the saved depth images in .npy format\n",
    "\n",
    "#camera information based on the Kinect v2 hardware\n",
    "CameraParams = {\n",
    "  \"cx\":254.878,\n",
    "  \"cy\":205.395,\n",
    "  \"fx\":365.456,\n",
    "  \"fy\":365.456,\n",
    "  \"k1\":0.0905474,\n",
    "  \"k2\":-0.26819,\n",
    "  \"k3\":0.0950862,\n",
    "  \"p1\":0.0,\n",
    "  \"p2\":0.0,\n",
    "}\n",
    "\n",
    "# Kinect's physical orientation in the real world.\n",
    "CameraPosition = {\n",
    "    \"x\": 0, # actual position in meters of kinect sensor relative to the viewport's center.\n",
    "    \"y\": 0, # actual position in meters of kinect sensor relative to the viewport's center.\n",
    "    \"z\": 0, # height in meters of actual kinect sensor from the floor.\n",
    "    \"roll\": 0, # angle in degrees of sensor's roll (used for INU input - trig function for this is commented out by default).\n",
    "    \"azimuth\": 0, # sensor's yaw angle in degrees.\n",
    "    \"elevation\": -30, # sensor's pitch angle in degrees.\n",
    "}\n",
    "\n",
    "def depthMatrixToPointCloudPos(z, scale=1000):\n",
    "    \"\"\"\n",
    "    xyz_arr = depthMatrixToPointCloudPos(depth_frame)\n",
    "\n",
    "    Given a depth image, converts each\n",
    "    point to an XYZ coordinate and returns\n",
    "    an array of these points.\n",
    "    The scale is a conversion factor.\n",
    "    Default converts from milimeter\n",
    "    depth data to meters.\n",
    "    \"\"\"\n",
    "    C, R = np.indices(z.shape)\n",
    "\n",
    "    R = np.subtract(R, CameraParams['cx'])\n",
    "    R = np.multiply(R, z)\n",
    "    R = np.divide(R, CameraParams['fx'] * scale)\n",
    "\n",
    "    C = np.subtract(C, CameraParams['cy'])\n",
    "    C = np.multiply(C, z)\n",
    "    C = np.divide(C, CameraParams['fy'] * scale)\n",
    "\n",
    "    return np.column_stack((z.ravel() / scale, R.ravel(), -C.ravel()))\n",
    "\n",
    "def depthToPointCloudPos(x_d, y_d, z, scale=1000):\n",
    "    \"\"\"\n",
    "    x, y, z = (row, col, depth)\n",
    "    \n",
    "    Given a point from a depth image\n",
    "    and its position in the image,\n",
    "    returns the x, y, and z coordinates\n",
    "    relative to the camera location.\n",
    "    The scale is a conversion factor.\n",
    "    Default converts from milimeter\n",
    "    depth data to meters.\n",
    "    \"\"\"\n",
    "    x = (x_d - CameraParams['cx']) * z / CameraParams['fx']\n",
    "    y = (y_d - CameraParams['cy']) * z / CameraParams['fy']\n",
    "\n",
    "    return x / scale, y / scale, z / scale\n",
    "\n",
    "def applyCameraOrientation(pt):\n",
    "    # Kinect Sensor Orientation Compensation\n",
    "    # This runs slowly in Python as it is required to be called within a loop, but it is a more intuitive example than it's vertorized alternative (Purly for example)\n",
    "    # use trig to rotate a vertex around a gimbal.\n",
    "    def rotatePoints(ax1, ax2, deg):\n",
    "        # math to rotate vertexes around a center point on a plane.\n",
    "        hyp = np.sqrt(pt[ax1] ** 2 + pt[ax2] ** 2) # Get the length of the hypotenuse of the real-world coordinate from center of rotation, this is the radius!\n",
    "        d_tan = np.arctan2(pt[ax2], pt[ax1]) # Calculate the vertexes current angle (returns radians that go from -180 to 180)\n",
    "\n",
    "        cur_angle = np.degrees(d_tan) % 360 # Convert radians to degrees and use modulo to adjust range from 0 to 360.\n",
    "        new_angle = np.radians((cur_angle + deg) % 360) # The new angle (in radians) of the vertexes after being rotated by the value of deg.\n",
    "\n",
    "        pt[ax1] = hyp * np.cos(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "        pt[ax2] = hyp * np.sin(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "\n",
    "    #rotatePoints(0, 2, CameraPosition['roll']) #rotate on the Y&Z plane # Disabled because most tripods don't roll. If an Inertial Nav Unit is available this could be used)\n",
    "    rotatePoints(1, 2, CameraPosition['elevation']) #rotate on the X&Z plane\n",
    "    rotatePoints(0, 1, CameraPosition['azimuth']) #rotate on the X&Y plane\n",
    "\n",
    "    # Apply offsets for height and linear position of the sensor (from viewport's center)\n",
    "    pt[:] += np.float_([CameraPosition['x'], CameraPosition['y'], CameraPosition['z']])\n",
    "    return pt\n",
    "\n",
    "def applyCameraMatrixOrientation(pt):\n",
    "    # Kinect Sensor Orientation Compensation\n",
    "    # bacically this is a vectorized version of applyCameraOrientation()\n",
    "    # uses same trig to rotate a vertex around a gimbal.\n",
    "    def rotatePoints(ax1, ax2, deg):\n",
    "        # math to rotate vertexes around a center point on a plane.\n",
    "        hyp = np.sqrt(pt[:, ax1] ** 2 + pt[:, ax2] ** 2) # Get the length of the hypotenuse of the real-world coordinate from center of rotation, this is the radius!\n",
    "        d_tan = np.arctan2(pt[:, ax2], pt[:, ax1]) # Calculate the vertexes current angle (returns radians that go from -180 to 180)\n",
    "\n",
    "        cur_angle = np.degrees(d_tan) % 360 # Convert radians to degrees and use modulo to adjust range from 0 to 360.\n",
    "        new_angle = np.radians((cur_angle + deg) % 360) # The new angle (in radians) of the vertexes after being rotated by the value of deg.\n",
    "\n",
    "        pt[:, ax1] = hyp * np.cos(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "        pt[:, ax2] = hyp * np.sin(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "\n",
    "    #rotatePoints(1, 2, CameraPosition['roll']) #rotate on the Y&Z plane # Disabled because most tripods don't roll. If an Inertial Nav Unit is available this could be used)\n",
    "    rotatePoints(0, 2, CameraPosition['elevation']) #rotate on the X&Z plane\n",
    "    rotatePoints(0, 1, CameraPosition['azimuth']) #rotate on the X&Y\n",
    "\n",
    "    # Apply offsets for height and linear position of the sensor (from viewport's center)\n",
    "    pt[:] += np.float_([CameraPosition['x'], CameraPosition['y'], CameraPosition['z']])\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plane_fit(points):\n",
    "    \"\"\"\n",
    "    p, n = plane_fit(points)\n",
    "\n",
    "    Given an array, points, of shape (d,...)\n",
    "    representing points in d-dimensional space,\n",
    "    fit an d-dimensional plane to the points.\n",
    "    Return a point, p, on the plane (the point-cloud centroid),\n",
    "    and the normal, n.\n",
    "    \"\"\"\n",
    "    from numpy.linalg import svd\n",
    "    points = np.reshape(points, (np.shape(points)[0], -1)) # Collapse trialing dimensions\n",
    "    assert points.shape[0] <= points.shape[1], \"There are only {} points in {} dimensions.\".format(points.shape[1], points.shape[0])\n",
    "    ctr = points.mean(axis=1)\n",
    "    x = points - ctr[:,np.newaxis]\n",
    "    M = np.dot(x, x.T) # Could also use np.cov(x) here.\n",
    "    return ctr, svd(M)[0][:,-1]\n",
    "\n",
    "def get_orientation(xyz_arr, n_iter):\n",
    "    \"\"\"\n",
    "    center, plane, theta = get_orientation(xyz_arr, num_points)\n",
    "\n",
    "    Given an array, points, of shape (d,...)\n",
    "    representing points in d-dimensional space,\n",
    "    fits a plane to the array n_iter times and\n",
    "    returns the average of the planes centers,\n",
    "    norms, and pitch degrees.\n",
    "    \"\"\"\n",
    "    pitch = []\n",
    "    planes = []\n",
    "    centers = []\n",
    "    for _ in range(0, n_iter):\n",
    "        rand_points = []\n",
    "        while len(rand_points) < 10:\n",
    "            index = random.randrange(0,len(xyz_arr))\n",
    "            if not xyz_arr[index].all() == np.zeros(3).all():\n",
    "                rand_points.append(xyz_arr[index])\n",
    "        rand_points = np.array(rand_points).T\n",
    "        ctr, P = plane_fit(rand_points)\n",
    "        r = math.sqrt(P[0]**2 + P[1]**2 + P[2]**2)\n",
    "        theta = math.acos(P[2]/r) * 180 / math.pi\n",
    "        phi = math.atan(P[1]/P[0]) * 180 / math.pi\n",
    "        pitch.append(theta)\n",
    "        planes.append(P)\n",
    "        centers.append(ctr)\n",
    "    return np.mean(centers, axis = 0), np.mean(planes, axis = 0), np.mean(pitch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import os, os.path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def get_obstacles_with_plane(depth_frame, num_planes, num_points, dist_thresh, visualize):\n",
    "    obstacles = np.zeros(depth_frame.shape) #empty image that will store the locations of detected obstacles\n",
    "    img = np.uint8(depth_frame) #some opencv functions require a byte image\n",
    "\n",
    "    xyz_arr = depthMatrixToPointCloudPos(depth_frame) #convert depth data to XYZ coordinates\n",
    "    start_time = time.time()\n",
    "    center, plane, theta = get_orientation(xyz_arr, num_points)\n",
    "    CameraPosition['elevation'] = -theta\n",
    "    center = applyCameraOrientation(center)\n",
    "    plane = applyCameraOrientation(plane)\n",
    "    xyz_arr = applyCameraMatrixOrientation(xyz_arr)\n",
    "    plane_img = np.zeros(len(xyz_arr))\n",
    "    plane_img[xyz_arr[:,2] > dist_thresh - center[2]] = 1\n",
    "    if visualize:\n",
    "        xyz_arr = xyz_arr[xyz_arr[:,2] > dist_thresh - center[2]]\n",
    "        points = pd.DataFrame(xyz_arr, columns=['x', 'y', 'z']) #convert XYZ coordinates to a DataFrame for pyntcloud\n",
    "        cloud = PyntCloud(points)\n",
    "\n",
    "        lines = [\n",
    "            {\n",
    "                # X axis\n",
    "                \"color\": \"red\", \n",
    "                \"vertices\": [[0, 0, 0], [10, 0, 0]]\n",
    "            },\n",
    "            {\n",
    "                # Y axis\n",
    "                \"color\": \"green\",\n",
    "                \"vertices\": [[0, 0, 0], [0, 10, 0]]\n",
    "            },\n",
    "            {\n",
    "                # Z axis\n",
    "                \"color\": \"blue\",\n",
    "                \"vertices\": [[0, 0, 0], [0, 0, 10]]\n",
    "            },\n",
    "            {\n",
    "                #Original norm of the plane\n",
    "                \"color\": \"pink\",\n",
    "                \"vertices\": [center.tolist(), plane.tolist()]\n",
    "            }\n",
    "        ]\n",
    "        cloud.plot(cmap=\"cool\", polylines=lines)\n",
    "\n",
    "    plane_img = np.uint8(np.reshape(plane_img,(424,512)) * 255) #reshape to match depth data and convert to uint8\n",
    "    plane_img = np.uint8((np.ones((424,512)) * 255) - plane_img) #invert img so pixel value corresponds to NOT ground plane\n",
    "    ret, plane_img = cv2.threshold(plane_img,0,255,cv2.THRESH_BINARY) #filter points that are probaly not ground plane\n",
    "    plane_img = cv2.subtract(img, plane_img)\n",
    "    \n",
    "    #noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(plane_img ,cv2.MORPH_OPEN, kernel, iterations = 3) #erosion followed by dilation\n",
    "\n",
    "    color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) #BGR image to draw labels on\n",
    "\n",
    "    #begin contour detection\n",
    "    image, contours, hierarchy = cv2.findContours(opening,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    color = cv2.drawContours(color, contours, -1, (0,255,0), 1)\n",
    "    for cntr in contours:\n",
    "        try:\n",
    "            #calculate diamter of equivalent circle\n",
    "            #this measurement is only used for checking if countours fit our bounds\n",
    "            area = cv2.contourArea(cntr)\n",
    "            equi_diameter = np.sqrt(4*area/np.pi)\n",
    "\n",
    "            #Hardcoded Diameter Range in pixels\n",
    "            LOW_DIAMETER_BOUND = 20\n",
    "            HIGH_DIAMETER_BOUND = 150\n",
    "\n",
    "            HIGH_DISTANCE_BOUND = 4500\n",
    "            #Original tolerances were 20 and 150\n",
    "\n",
    "            if(equi_diameter>LOW_DIAMETER_BOUND and equi_diameter<HIGH_DIAMETER_BOUND):\n",
    "                mask = np.zeros_like(img) #mask will contain the fitted and adjusted ellipse of a single obstacle\n",
    "                ellipse = cv2.fitEllipse(cntr)\n",
    "                x,y,obj_length,obj_height = cv2.boundingRect(cntr)\n",
    "                rect = cv2.minAreaRect(cntr)\n",
    "\n",
    "                equi_diameter = obj_length #bounding rectangle gives a better approximation of diameter\n",
    "\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                mask = cv2.ellipse(mask,ellipse,(255,255,255),-1) #draw the fitted ellipse\n",
    "                rows = mask.shape[0]\n",
    "                cols = mask.shape[1]\n",
    "                M = np.float32([[1,0,0],[0,1,equi_diameter/4]]) #shift mask down to match obstacle, not edge\n",
    "                mask = cv2.warpAffine(mask,M,(cols,rows))\n",
    "                mask = cv2.erode(mask, kernel, iterations=3) #erode the mask to remove background points\n",
    "                img_fg = cv2.bitwise_and(depth_frame,depth_frame,mask = mask) #use the mask to isolate original depth values\n",
    "                img_fg = cv2.medianBlur(img_fg,5) #median blur to further remove noise\n",
    "                obstacles = cv2.add(np.float32(img_fg), np.float32(obstacles)) \n",
    "                \n",
    "                mean_val = np.median(img_fg[img_fg.nonzero()]) #compute the non-zero average of obstacle depth values\n",
    "                min_val, distance_to_object, min_loc, max_loc = cv2.minMaxLoc(img_fg)\n",
    "\n",
    "                moment = cv2.moments(cntr) #get the centroid of the obstacle using its moment\n",
    "                cx = int(moment['m10']/moment['m00'])\n",
    "                cy = int(moment['m01']/moment['m00'])\n",
    "\n",
    "                if mean_val < HIGH_DISTANCE_BOUND: #kinect loses accuracy beyond 4.5m\n",
    "                    coords = depthToPointCloudPos(cx, cy, mean_val) #convert obstacle depth to XYZ coordinate\n",
    "\n",
    "                    mm_diameter = (equi_diameter) * (1.0 / CameraParams['fx']) * mean_val #convert pixel diameter to mm\n",
    "\n",
    "                    #begin visualization\n",
    "                    cv2.drawContours(color,[box],0,(0,0,255),1)\n",
    "                    cv2.rectangle(color,(x,y),(x+obj_length,y+obj_height),(0,255,0),2)\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(color, \"x\" + str(coords[0]), (cx,cy+30), font, 0.4, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color, \"y\" + str(coords[1]), (cx,cy+45), font, 0.4, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color, \"z\" + str(mean_val), (cx,cy+60), font, 0.4, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color,\"diameter = \" + str(mm_diameter), (cx,cy + 15), font, 0.4, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        except:\n",
    "            print (\"Failed to process image\")\n",
    "            print (sys.exc_info()[0])\n",
    "            \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Frame took \" + str(elapsed_time) + \" seconds to process\")\n",
    "\n",
    "    cv2.imshow(\"plane\",plane_img)\n",
    "    cv2.imshow(\"img\",depth_frame)\n",
    "    cv2.imshow(\"final\",color)\n",
    "    cv2.imshow(\"sure_bg\",opening)\n",
    "    cv2.imshow(\"obstacles\",obstacles)\n",
    "    key = cv2.waitKey(delay=1)\n",
    "    return color\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\pythreejs\\traits.py:175: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8debc07356d24c029046a2f33544e9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(0.018213037384957196, 0.49344487097691464, 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22c98e5029b4acd83f6c975c85519d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.2626247799854516, max=2.6262477998545157, step=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.5736684799194336 seconds to process\n"
     ]
    }
   ],
   "source": [
    "img = np.load('kinect_data/116.npy')\n",
    "output = get_obstacles_with_plane(img, num_planes = 10, \n",
    "                                  num_points = 5, \n",
    "                                  dist_thresh = 0.1, \n",
    "                                  visualize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The Windows bytes API has been deprecated, use Unicode filenames instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinect_data/0.npy\n",
      "Frame took 0.06593751907348633 seconds to process\n",
      "kinect_data/1.npy\n",
      "Frame took 0.05898571014404297 seconds to process\n",
      "kinect_data/10.npy\n",
      "Frame took 0.06596040725708008 seconds to process\n",
      "kinect_data/100.npy\n",
      "Frame took 0.07397031784057617 seconds to process\n",
      "kinect_data/101.npy\n",
      "Frame took 0.06296205520629883 seconds to process\n",
      "kinect_data/102.npy\n",
      "Frame took 0.08093380928039551 seconds to process\n",
      "kinect_data/103.npy\n",
      "Frame took 0.0719766616821289 seconds to process\n",
      "kinect_data/104.npy\n",
      "Frame took 0.054947853088378906 seconds to process\n",
      "kinect_data/105.npy\n",
      "Frame took 0.06396293640136719 seconds to process\n",
      "kinect_data/106.npy\n",
      "Frame took 0.06694626808166504 seconds to process\n",
      "kinect_data/107.npy\n",
      "Frame took 0.07595467567443848 seconds to process\n",
      "kinect_data/108.npy\n",
      "Frame took 0.06096315383911133 seconds to process\n",
      "kinect_data/109.npy\n",
      "Frame took 0.06396365165710449 seconds to process\n",
      "kinect_data/11.npy\n",
      "Frame took 0.1669013500213623 seconds to process\n",
      "kinect_data/110.npy\n",
      "Frame took 0.06196427345275879 seconds to process\n",
      "kinect_data/111.npy\n",
      "Frame took 0.05996346473693848 seconds to process\n",
      "kinect_data/112.npy\n",
      "Frame took 0.06995987892150879 seconds to process\n",
      "kinect_data/113.npy\n",
      "Frame took 0.06696176528930664 seconds to process\n",
      "kinect_data/114.npy\n",
      "Frame took 0.05696702003479004 seconds to process\n",
      "kinect_data/115.npy\n",
      "Frame took 0.0559847354888916 seconds to process\n",
      "kinect_data/116.npy\n",
      "Frame took 0.061963796615600586 seconds to process\n",
      "kinect_data/117.npy\n",
      "Frame took 0.07896685600280762 seconds to process\n",
      "kinect_data/118.npy\n",
      "Frame took 0.0619661808013916 seconds to process\n",
      "kinect_data/119.npy\n",
      "Frame took 0.07896757125854492 seconds to process\n",
      "kinect_data/12.npy\n",
      "Frame took 0.06094217300415039 seconds to process\n",
      "kinect_data/120.npy\n",
      "Frame took 0.08494830131530762 seconds to process\n",
      "kinect_data/121.npy\n",
      "Frame took 0.061963558197021484 seconds to process\n",
      "kinect_data/122.npy\n",
      "Frame took 0.06396079063415527 seconds to process\n",
      "kinect_data/123.npy\n",
      "Frame took 0.058965444564819336 seconds to process\n",
      "kinect_data/124.npy\n",
      "Frame took 0.06596016883850098 seconds to process\n",
      "kinect_data/125.npy\n",
      "Frame took 0.05394864082336426 seconds to process\n",
      "kinect_data/126.npy\n",
      "Frame took 0.06494975090026855 seconds to process\n",
      "kinect_data/127.npy\n",
      "Frame took 0.054967641830444336 seconds to process\n",
      "kinect_data/128.npy\n",
      "Frame took 0.28783464431762695 seconds to process\n",
      "kinect_data/129.npy\n",
      "Frame took 0.05596590042114258 seconds to process\n",
      "kinect_data/13.npy\n",
      "Frame took 0.06096529960632324 seconds to process\n",
      "kinect_data/130.npy\n",
      "Frame took 0.06596040725708008 seconds to process\n",
      "kinect_data/131.npy\n",
      "Frame took 0.07095861434936523 seconds to process\n",
      "kinect_data/132.npy\n",
      "Frame took 0.07095456123352051 seconds to process\n",
      "kinect_data/133.npy\n",
      "Frame took 0.06495976448059082 seconds to process\n",
      "kinect_data/134.npy\n",
      "Frame took 0.06897687911987305 seconds to process\n",
      "kinect_data/135.npy\n",
      "Frame took 0.06696414947509766 seconds to process\n",
      "kinect_data/136.npy\n",
      "Frame took 0.07497000694274902 seconds to process\n",
      "kinect_data/137.npy\n",
      "Frame took 0.0639491081237793 seconds to process\n",
      "kinect_data/138.npy\n",
      "Frame took 0.06396245956420898 seconds to process\n",
      "kinect_data/139.npy\n",
      "Frame took 0.054984331130981445 seconds to process\n",
      "kinect_data/14.npy\n",
      "Frame took 0.05896401405334473 seconds to process\n",
      "kinect_data/140.npy\n",
      "Frame took 0.07295536994934082 seconds to process\n",
      "kinect_data/141.npy\n",
      "Frame took 0.0599668025970459 seconds to process\n",
      "kinect_data/142.npy\n",
      "Frame took 0.05396699905395508 seconds to process\n",
      "kinect_data/143.npy\n",
      "Frame took 0.05896568298339844 seconds to process\n",
      "kinect_data/144.npy\n",
      "Frame took 0.06596231460571289 seconds to process\n",
      "kinect_data/145.npy\n",
      "Frame took 0.06096339225769043 seconds to process\n",
      "kinect_data/146.npy\n",
      "Frame took 0.05896425247192383 seconds to process\n",
      "kinect_data/147.npy\n",
      "Frame took 0.2528548240661621 seconds to process\n",
      "kinect_data/148.npy\n",
      "Frame took 0.05896592140197754 seconds to process\n",
      "kinect_data/149.npy\n",
      "Frame took 0.06496310234069824 seconds to process\n",
      "kinect_data/15.npy\n",
      "Frame took 0.05796480178833008 seconds to process\n",
      "kinect_data/150.npy\n",
      "Frame took 0.0699758529663086 seconds to process\n",
      "kinect_data/151.npy\n",
      "Frame took 0.06695890426635742 seconds to process\n",
      "kinect_data/152.npy\n",
      "Frame took 0.06496047973632812 seconds to process\n",
      "kinect_data/153.npy\n",
      "Frame took 0.06895709037780762 seconds to process\n",
      "kinect_data/154.npy\n",
      "Frame took 0.06595492362976074 seconds to process\n",
      "kinect_data/155.npy\n",
      "Frame took 0.07195758819580078 seconds to process\n",
      "kinect_data/156.npy\n",
      "Frame took 0.06096363067626953 seconds to process\n",
      "kinect_data/157.npy\n",
      "Frame took 0.061963796615600586 seconds to process\n",
      "kinect_data/158.npy\n",
      "Frame took 0.06096982955932617 seconds to process\n",
      "kinect_data/159.npy\n",
      "Frame took 0.06397628784179688 seconds to process\n",
      "kinect_data/16.npy\n",
      "Frame took 0.05296921730041504 seconds to process\n",
      "kinect_data/160.npy\n",
      "Frame took 0.06695699691772461 seconds to process\n",
      "kinect_data/161.npy\n",
      "Frame took 0.06496071815490723 seconds to process\n",
      "kinect_data/162.npy\n",
      "Frame took 0.06595945358276367 seconds to process\n",
      "kinect_data/163.npy\n",
      "Frame took 0.06496095657348633 seconds to process\n",
      "kinect_data/164.npy\n",
      "Frame took 0.05997920036315918 seconds to process\n",
      "kinect_data/165.npy\n",
      "Frame took 0.06796073913574219 seconds to process\n",
      "kinect_data/166.npy\n",
      "Frame took 0.2288665771484375 seconds to process\n",
      "kinect_data/167.npy\n",
      "Frame took 0.06596183776855469 seconds to process\n",
      "kinect_data/168.npy\n",
      "Frame took 0.06096506118774414 seconds to process\n",
      "kinect_data/169.npy\n",
      "Frame took 0.06396293640136719 seconds to process\n",
      "kinect_data/17.npy\n",
      "Frame took 0.05696678161621094 seconds to process\n",
      "kinect_data/170.npy\n",
      "Frame took 0.06396293640136719 seconds to process\n",
      "kinect_data/171.npy\n",
      "Frame took 0.06296992301940918 seconds to process\n",
      "kinect_data/172.npy\n",
      "Frame took 0.06895899772644043 seconds to process\n",
      "kinect_data/173.npy\n",
      "Frame took 0.059983253479003906 seconds to process\n",
      "kinect_data/174.npy\n",
      "Frame took 0.06897139549255371 seconds to process\n",
      "kinect_data/175.npy\n",
      "Frame took 0.06229567527770996 seconds to process\n",
      "kinect_data/176.npy\n",
      "Frame took 0.05499100685119629 seconds to process\n",
      "kinect_data/177.npy\n",
      "Frame took 0.06304287910461426 seconds to process\n",
      "kinect_data/178.npy\n",
      "Frame took 0.06795144081115723 seconds to process\n",
      "kinect_data/179.npy\n",
      "Frame took 0.06997799873352051 seconds to process\n",
      "kinect_data/18.npy\n",
      "Frame took 0.06194901466369629 seconds to process\n",
      "kinect_data/180.npy\n",
      "Frame took 0.06795907020568848 seconds to process\n",
      "kinect_data/181.npy\n",
      "Frame took 0.06094527244567871 seconds to process\n",
      "kinect_data/182.npy\n",
      "Frame took 0.05996274948120117 seconds to process\n",
      "kinect_data/183.npy\n",
      "Frame took 0.06603479385375977 seconds to process\n",
      "kinect_data/184.npy\n",
      "Frame took 0.06995677947998047 seconds to process\n",
      "kinect_data/185.npy\n",
      "Frame took 0.15990710258483887 seconds to process\n",
      "kinect_data/186.npy\n",
      "Frame took 0.13192200660705566 seconds to process\n",
      "kinect_data/187.npy\n",
      "Frame took 0.06496191024780273 seconds to process\n",
      "kinect_data/188.npy\n",
      "Frame took 0.06198930740356445 seconds to process\n",
      "kinect_data/189.npy\n",
      "Frame took 0.07294178009033203 seconds to process\n",
      "kinect_data/19.npy\n",
      "Frame took 0.05996513366699219 seconds to process\n",
      "kinect_data/190.npy\n",
      "Frame took 0.06596016883850098 seconds to process\n",
      "kinect_data/191.npy\n",
      "Frame took 0.06296253204345703 seconds to process\n",
      "kinect_data/192.npy\n",
      "Frame took 0.06501007080078125 seconds to process\n",
      "kinect_data/193.npy\n",
      "Frame took 0.057471513748168945 seconds to process\n",
      "kinect_data/194.npy\n",
      "Frame took 0.06995868682861328 seconds to process\n",
      "kinect_data/195.npy\n",
      "Frame took 0.05999946594238281 seconds to process\n",
      "kinect_data/196.npy\n",
      "Frame took 0.06895065307617188 seconds to process\n",
      "kinect_data/197.npy\n",
      "Frame took 0.05496549606323242 seconds to process\n",
      "kinect_data/198.npy\n",
      "Frame took 0.06396150588989258 seconds to process\n",
      "kinect_data/199.npy\n",
      "Frame took 0.08594918251037598 seconds to process\n",
      "kinect_data/2.npy\n",
      "Frame took 0.05696678161621094 seconds to process\n",
      "kinect_data/20.npy\n",
      "Frame took 0.05498385429382324 seconds to process\n",
      "kinect_data/200.npy\n",
      "Frame took 0.06425833702087402 seconds to process\n",
      "kinect_data/201.npy\n",
      "Frame took 0.059964895248413086 seconds to process\n",
      "kinect_data/202.npy\n",
      "Frame took 0.05997037887573242 seconds to process\n",
      "kinect_data/203.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.07099366188049316 seconds to process\n",
      "kinect_data/204.npy\n",
      "Frame took 0.26184916496276855 seconds to process\n",
      "kinect_data/205.npy\n",
      "Frame took 0.05717110633850098 seconds to process\n",
      "kinect_data/206.npy\n",
      "Frame took 0.05596756935119629 seconds to process\n",
      "kinect_data/207.npy\n",
      "Frame took 0.06696224212646484 seconds to process\n",
      "kinect_data/208.npy\n",
      "Frame took 0.05596590042114258 seconds to process\n",
      "kinect_data/209.npy\n",
      "Frame took 0.05796456336975098 seconds to process\n",
      "kinect_data/21.npy\n",
      "Frame took 0.05496835708618164 seconds to process\n",
      "kinect_data/210.npy\n",
      "Frame took 0.05497169494628906 seconds to process\n",
      "kinect_data/211.npy\n",
      "Frame took 0.0599515438079834 seconds to process\n",
      "kinect_data/212.npy\n",
      "Frame took 0.05897188186645508 seconds to process\n",
      "kinect_data/213.npy\n",
      "Frame took 0.054967403411865234 seconds to process\n",
      "kinect_data/214.npy\n",
      "Frame took 0.05596423149108887 seconds to process\n",
      "kinect_data/215.npy\n",
      "Frame took 0.05894827842712402 seconds to process\n",
      "kinect_data/216.npy\n",
      "Frame took 0.05396842956542969 seconds to process\n",
      "kinect_data/217.npy\n",
      "Frame took 0.05594611167907715 seconds to process\n",
      "kinect_data/218.npy\n",
      "Frame took 0.06096363067626953 seconds to process\n",
      "kinect_data/219.npy\n",
      "Frame took 0.05596733093261719 seconds to process\n",
      "kinect_data/22.npy\n",
      "Frame took 0.07095932960510254 seconds to process\n",
      "kinect_data/220.npy\n",
      "Frame took 0.05494546890258789 seconds to process\n",
      "kinect_data/221.npy\n",
      "Frame took 0.058965444564819336 seconds to process\n",
      "kinect_data/222.npy\n",
      "Frame took 0.05496549606323242 seconds to process\n",
      "kinect_data/223.npy\n",
      "Frame took 0.05894827842712402 seconds to process\n",
      "kinect_data/224.npy\n",
      "Frame took 0.21987414360046387 seconds to process\n",
      "kinect_data/225.npy\n",
      "Frame took 0.07395720481872559 seconds to process\n",
      "kinect_data/226.npy\n",
      "Frame took 0.0549473762512207 seconds to process\n",
      "kinect_data/227.npy\n",
      "Frame took 0.056946516036987305 seconds to process\n",
      "kinect_data/228.npy\n",
      "Frame took 0.061964988708496094 seconds to process\n",
      "kinect_data/229.npy\n",
      "Frame took 0.05746817588806152 seconds to process\n",
      "kinect_data/23.npy\n",
      "Frame took 0.07295727729797363 seconds to process\n",
      "kinect_data/24.npy\n",
      "Frame took 0.06795883178710938 seconds to process\n",
      "kinect_data/25.npy\n",
      "Frame took 0.053968191146850586 seconds to process\n",
      "kinect_data/26.npy\n",
      "Frame took 0.07396721839904785 seconds to process\n",
      "kinect_data/27.npy\n",
      "Frame took 0.05494499206542969 seconds to process\n",
      "kinect_data/28.npy\n",
      "Frame took 0.05898284912109375 seconds to process\n",
      "kinect_data/29.npy\n",
      "Frame took 0.05596637725830078 seconds to process\n",
      "kinect_data/3.npy\n",
      "Frame took 0.05695319175720215 seconds to process\n",
      "kinect_data/30.npy\n",
      "Frame took 0.06725955009460449 seconds to process\n",
      "kinect_data/31.npy\n",
      "Frame took 0.06296038627624512 seconds to process\n",
      "kinect_data/32.npy\n",
      "Frame took 0.06196331977844238 seconds to process\n",
      "kinect_data/33.npy\n",
      "Frame took 0.06097865104675293 seconds to process\n",
      "kinect_data/34.npy\n",
      "Frame took 0.06695723533630371 seconds to process\n",
      "kinect_data/35.npy\n",
      "Frame took 0.06795239448547363 seconds to process\n",
      "kinect_data/36.npy\n",
      "Frame took 0.06096339225769043 seconds to process\n",
      "kinect_data/37.npy\n",
      "Frame took 0.21985244750976562 seconds to process\n",
      "kinect_data/38.npy\n",
      "Frame took 0.05498456954956055 seconds to process\n",
      "kinect_data/39.npy\n",
      "Frame took 0.07494306564331055 seconds to process\n",
      "kinect_data/4.npy\n",
      "Frame took 0.06394290924072266 seconds to process\n",
      "kinect_data/40.npy\n",
      "Frame took 0.07295775413513184 seconds to process\n",
      "kinect_data/41.npy\n",
      "Frame took 0.06524085998535156 seconds to process\n",
      "kinect_data/42.npy\n",
      "Frame took 0.06995034217834473 seconds to process\n",
      "kinect_data/43.npy\n",
      "Frame took 0.06014132499694824 seconds to process\n",
      "kinect_data/44.npy\n",
      "Frame took 0.0549619197845459 seconds to process\n",
      "kinect_data/45.npy\n",
      "Frame took 0.06294465065002441 seconds to process\n",
      "kinect_data/46.npy\n",
      "Frame took 0.05495023727416992 seconds to process\n",
      "kinect_data/47.npy\n",
      "Frame took 0.06795573234558105 seconds to process\n",
      "kinect_data/48.npy\n",
      "Frame took 0.07105827331542969 seconds to process\n",
      "kinect_data/49.npy\n",
      "Frame took 0.05697298049926758 seconds to process\n",
      "kinect_data/5.npy\n",
      "Frame took 0.05494832992553711 seconds to process\n",
      "kinect_data/50.npy\n",
      "Frame took 0.07693195343017578 seconds to process\n",
      "kinect_data/51.npy\n",
      "Frame took 0.06595873832702637 seconds to process\n",
      "kinect_data/52.npy\n",
      "Frame took 0.06096696853637695 seconds to process\n",
      "kinect_data/53.npy\n",
      "Frame took 0.06997466087341309 seconds to process\n",
      "kinect_data/54.npy\n",
      "Frame took 0.06796050071716309 seconds to process\n",
      "kinect_data/55.npy\n",
      "Frame took 0.06995558738708496 seconds to process\n",
      "kinect_data/56.npy\n",
      "Frame took 0.266845703125 seconds to process\n",
      "kinect_data/57.npy\n",
      "Frame took 0.07197117805480957 seconds to process\n",
      "kinect_data/58.npy\n",
      "Frame took 0.06497621536254883 seconds to process\n",
      "kinect_data/59.npy\n",
      "Frame took 0.07120347023010254 seconds to process\n",
      "kinect_data/6.npy\n",
      "Frame took 0.05498480796813965 seconds to process\n",
      "kinect_data/60.npy\n",
      "Frame took 0.060981035232543945 seconds to process\n",
      "kinect_data/61.npy\n",
      "Frame took 0.0699770450592041 seconds to process\n",
      "kinect_data/62.npy\n",
      "Frame took 0.07095074653625488 seconds to process\n",
      "kinect_data/63.npy\n",
      "Frame took 0.07232666015625 seconds to process\n",
      "kinect_data/64.npy\n",
      "Frame took 0.05894589424133301 seconds to process\n",
      "kinect_data/65.npy\n",
      "Frame took 0.07095718383789062 seconds to process\n",
      "kinect_data/66.npy\n",
      "Frame took 0.06497573852539062 seconds to process\n",
      "kinect_data/67.npy\n",
      "Frame took 0.05994558334350586 seconds to process\n",
      "kinect_data/68.npy\n",
      "Frame took 0.07696866989135742 seconds to process\n",
      "kinect_data/69.npy\n",
      "Frame took 0.07295823097229004 seconds to process\n",
      "kinect_data/7.npy\n",
      "Frame took 0.055967092514038086 seconds to process\n",
      "kinect_data/70.npy\n",
      "Frame took 0.07297325134277344 seconds to process\n",
      "kinect_data/71.npy\n",
      "Frame took 0.05396866798400879 seconds to process\n",
      "kinect_data/72.npy\n",
      "Frame took 0.053881168365478516 seconds to process\n",
      "kinect_data/73.npy\n",
      "Frame took 0.06596112251281738 seconds to process\n",
      "kinect_data/74.npy\n",
      "Frame took 0.05707120895385742 seconds to process\n",
      "kinect_data/75.npy\n",
      "Frame took 0.25984978675842285 seconds to process\n",
      "kinect_data/76.npy\n",
      "Frame took 0.06995987892150879 seconds to process\n",
      "kinect_data/77.npy\n",
      "Frame took 0.058965444564819336 seconds to process\n",
      "kinect_data/78.npy\n",
      "Frame took 0.07895255088806152 seconds to process\n",
      "kinect_data/79.npy\n",
      "Frame took 0.05496811866760254 seconds to process\n",
      "kinect_data/8.npy\n",
      "Frame took 0.05696558952331543 seconds to process\n",
      "kinect_data/80.npy\n",
      "Frame took 0.05495572090148926 seconds to process\n",
      "kinect_data/81.npy\n",
      "Frame took 0.05595684051513672 seconds to process\n",
      "kinect_data/82.npy\n",
      "Frame took 0.06694602966308594 seconds to process\n",
      "kinect_data/83.npy\n",
      "Frame took 0.06696486473083496 seconds to process\n",
      "kinect_data/84.npy\n",
      "Frame took 0.06496143341064453 seconds to process\n",
      "kinect_data/85.npy\n",
      "Frame took 0.05796623229980469 seconds to process\n",
      "kinect_data/86.npy\n",
      "Frame took 0.06495976448059082 seconds to process\n",
      "kinect_data/87.npy\n",
      "Frame took 0.06896042823791504 seconds to process\n",
      "kinect_data/88.npy\n",
      "Frame took 0.07595515251159668 seconds to process\n",
      "kinect_data/89.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\jumpr_000\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:105: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.08394813537597656 seconds to process\n",
      "kinect_data/9.npy\n",
      "Frame took 0.05494880676269531 seconds to process\n",
      "kinect_data/90.npy\n",
      "Frame took 0.07695412635803223 seconds to process\n",
      "kinect_data/91.npy\n",
      "Frame took 0.06596112251281738 seconds to process\n",
      "kinect_data/92.npy\n",
      "Frame took 0.06596016883850098 seconds to process\n",
      "kinect_data/93.npy\n",
      "Frame took 0.18187522888183594 seconds to process\n",
      "kinect_data/94.npy\n",
      "Frame took 0.06696009635925293 seconds to process\n",
      "kinect_data/95.npy\n",
      "Frame took 0.06597423553466797 seconds to process\n",
      "kinect_data/96.npy\n",
      "Frame took 0.05998587608337402 seconds to process\n",
      "kinect_data/97.npy\n",
      "Frame took 0.06895804405212402 seconds to process\n",
      "kinect_data/98.npy\n",
      "Frame took 0.05696702003479004 seconds to process\n",
      "kinect_data/99.npy\n",
      "Frame took 0.05996441841125488 seconds to process\n"
     ]
    }
   ],
   "source": [
    "frames_dir = 'kinect_data/'\n",
    "directory = os.fsencode(frames_dir)\n",
    "frame_i = 0\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".npy\"):\n",
    "        file_path = frames_dir + filename\n",
    "        print(file_path)\n",
    "        img = np.load(file_path)\n",
    "        try:\n",
    "            output = get_obstacles_with_plane(img, num_planes = 20, \n",
    "                                  num_points = 5, \n",
    "                                  dist_thresh = 0.1, \n",
    "                                  visualize = False)\n",
    "            cv2.imwrite(os.path.join(path ,filename[:-4] + '.png'), output)\n",
    "            frame_i += 1\n",
    "        except:\n",
    "            print(\"Could not find obstacles\")\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
