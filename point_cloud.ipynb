{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import os, os.path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "path = 'C:/Users/jumpr_000/Desktop/ransac_obstacle_detection/saved' #set to your desired path to save images in\n",
    "frames_dir = \"kinect_data/\" #the directory holding the saved depth images in .npy format\n",
    "\n",
    "#camera information based on the Kinect v2 hardware\n",
    "CameraParams = {\n",
    "  \"cx\":254.878,\n",
    "  \"cy\":205.395,\n",
    "  \"fx\":365.456,\n",
    "  \"fy\":365.456,\n",
    "  \"k1\":0.0905474,\n",
    "  \"k2\":-0.26819,\n",
    "  \"k3\":0.0950862,\n",
    "  \"p1\":0.0,\n",
    "  \"p2\":0.0,\n",
    "}\n",
    "\n",
    "# Kinect's physical orientation in the real world.\n",
    "CameraPosition = {\n",
    "    \"x\": 0, # actual position in meters of kinect sensor relative to the viewport's center.\n",
    "    \"y\": 0, # actual position in meters of kinect sensor relative to the viewport's center.\n",
    "    \"z\": 0, # height in meters of actual kinect sensor from the floor.\n",
    "    \"roll\": 0, # angle in degrees of sensor's roll (used for INU input - trig function for this is commented out by default).\n",
    "    \"azimuth\": 0, # sensor's yaw angle in degrees.\n",
    "    \"elevation\": -30, # sensor's pitch angle in degrees.\n",
    "}\n",
    "\n",
    "def depthMatrixToPointCloudPos(z, scale=1000):\n",
    "    \"\"\"\n",
    "    xyz_arr = depthMatrixToPointCloudPos(depth_frame)\n",
    "\n",
    "    Given a depth image, converts each\n",
    "    point to an XYZ coordinate and returns\n",
    "    an array of these points.\n",
    "    The scale is a conversion factor.\n",
    "    Default converts from milimeter\n",
    "    depth data to meters.\n",
    "    \"\"\"\n",
    "    C, R = np.indices(z.shape)\n",
    "\n",
    "    R = np.subtract(R, CameraParams['cx'])\n",
    "    R = np.multiply(R, z)\n",
    "    R = np.divide(R, CameraParams['fx'] * scale)\n",
    "\n",
    "    C = np.subtract(C, CameraParams['cy'])\n",
    "    C = np.multiply(C, z)\n",
    "    C = np.divide(C, CameraParams['fy'] * scale)\n",
    "\n",
    "    return np.column_stack((z.ravel() / scale, R.ravel(), -C.ravel()))\n",
    "\n",
    "def depthToPointCloudPos(x_d, y_d, z, scale=1000):\n",
    "    \"\"\"\n",
    "    x, y, z = (row, col, depth)\n",
    "    \n",
    "    Given a point from a depth image\n",
    "    and its position in the image,\n",
    "    returns the x, y, and z coordinates\n",
    "    relative to the camera location.\n",
    "    The scale is a conversion factor.\n",
    "    Default converts from milimeter\n",
    "    depth data to meters.\n",
    "    \"\"\"\n",
    "    x = (x_d - CameraParams['cx']) * z / CameraParams['fx']\n",
    "    y = (y_d - CameraParams['cy']) * z / CameraParams['fy']\n",
    "\n",
    "    return x / scale, y / scale, z / scale\n",
    "\n",
    "def applyCameraOrientation(pt):\n",
    "    # Kinect Sensor Orientation Compensation\n",
    "    # This runs slowly in Python as it is required to be called within a loop, but it is a more intuitive example than it's vertorized alternative (Purly for example)\n",
    "    # use trig to rotate a vertex around a gimbal.\n",
    "    def rotatePoints(ax1, ax2, deg):\n",
    "        # math to rotate vertexes around a center point on a plane.\n",
    "        hyp = np.sqrt(pt[ax1] ** 2 + pt[ax2] ** 2) # Get the length of the hypotenuse of the real-world coordinate from center of rotation, this is the radius!\n",
    "        d_tan = np.arctan2(pt[ax2], pt[ax1]) # Calculate the vertexes current angle (returns radians that go from -180 to 180)\n",
    "\n",
    "        cur_angle = np.degrees(d_tan) % 360 # Convert radians to degrees and use modulo to adjust range from 0 to 360.\n",
    "        new_angle = np.radians((cur_angle + deg) % 360) # The new angle (in radians) of the vertexes after being rotated by the value of deg.\n",
    "\n",
    "        pt[ax1] = hyp * np.cos(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "        pt[ax2] = hyp * np.sin(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "\n",
    "    #rotatePoints(0, 2, CameraPosition['roll']) #rotate on the Y&Z plane # Disabled because most tripods don't roll. If an Inertial Nav Unit is available this could be used)\n",
    "    rotatePoints(1, 2, CameraPosition['elevation']) #rotate on the X&Z plane\n",
    "    rotatePoints(0, 1, CameraPosition['azimuth']) #rotate on the X&Y plane\n",
    "\n",
    "    # Apply offsets for height and linear position of the sensor (from viewport's center)\n",
    "    pt[:] += np.float_([CameraPosition['x'], CameraPosition['y'], CameraPosition['z']])\n",
    "    return pt\n",
    "\n",
    "def applyCameraMatrixOrientation(pt):\n",
    "    # Kinect Sensor Orientation Compensation\n",
    "    # bacically this is a vectorized version of applyCameraOrientation()\n",
    "    # uses same trig to rotate a vertex around a gimbal.\n",
    "    def rotatePoints(ax1, ax2, deg):\n",
    "        # math to rotate vertexes around a center point on a plane.\n",
    "        hyp = np.sqrt(pt[:, ax1] ** 2 + pt[:, ax2] ** 2) # Get the length of the hypotenuse of the real-world coordinate from center of rotation, this is the radius!\n",
    "        d_tan = np.arctan2(pt[:, ax2], pt[:, ax1]) # Calculate the vertexes current angle (returns radians that go from -180 to 180)\n",
    "\n",
    "        cur_angle = np.degrees(d_tan) % 360 # Convert radians to degrees and use modulo to adjust range from 0 to 360.\n",
    "        new_angle = np.radians((cur_angle + deg) % 360) # The new angle (in radians) of the vertexes after being rotated by the value of deg.\n",
    "\n",
    "        pt[:, ax1] = hyp * np.cos(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "        pt[:, ax2] = hyp * np.sin(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "\n",
    "    #rotatePoints(1, 2, CameraPosition['roll']) #rotate on the Y&Z plane # Disabled because most tripods don't roll. If an Inertial Nav Unit is available this could be used)\n",
    "    rotatePoints(0, 2, CameraPosition['elevation']) #rotate on the X&Z plane\n",
    "    rotatePoints(0, 1, CameraPosition['azimuth']) #rotate on the X&Y\n",
    "\n",
    "    # Apply offsets for height and linear position of the sensor (from viewport's center)\n",
    "    pt[:] += np.float_([CameraPosition['x'], CameraPosition['y'], CameraPosition['z']])\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plane Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plane_fit(points):\n",
    "    \"\"\"\n",
    "    p, n = plane_fit(points)\n",
    "\n",
    "    Given an array, points, of shape (d,...)\n",
    "    representing points in d-dimensional space,\n",
    "    fit an d-dimensional plane to the points.\n",
    "    Return a point, p, on the plane (the point-cloud centroid),\n",
    "    and the normal, n.\n",
    "    \"\"\"\n",
    "    from numpy.linalg import svd\n",
    "    points = np.reshape(points, (np.shape(points)[0], -1)) # Collapse trialing dimensions\n",
    "    assert points.shape[0] <= points.shape[1], \"There are only {} points in {} dimensions.\".format(points.shape[1], points.shape[0])\n",
    "    ctr = points.mean(axis=1)\n",
    "    x = points - ctr[:,np.newaxis]\n",
    "    M = np.dot(x, x.T) # Could also use np.cov(x) here.\n",
    "    return ctr, svd(M)[0][:,-1]\n",
    "\n",
    "def get_orientation(xyz_arr, n_iter):\n",
    "    \"\"\"\n",
    "    center, plane, theta = get_orientation(xyz_arr, num_points)\n",
    "\n",
    "    Given an array, points, of shape (d,...)\n",
    "    representing points in d-dimensional space,\n",
    "    fits a plane to the array n_iter times and\n",
    "    returns the average of the planes centers,\n",
    "    norms, and pitch degrees.\n",
    "    \"\"\"\n",
    "    pitch = []\n",
    "    planes = []\n",
    "    centers = []\n",
    "    for _ in range(0, n_iter):\n",
    "        rand_points = []\n",
    "        while len(rand_points) < 10:\n",
    "            index = random.randrange(0,len(xyz_arr))\n",
    "            if not xyz_arr[index].all() == np.zeros(3).all():\n",
    "                rand_points.append(xyz_arr[index])\n",
    "        rand_points = np.array(rand_points).T\n",
    "        ctr, P = plane_fit(rand_points)\n",
    "        r = math.sqrt(P[0]**2 + P[1]**2 + P[2]**2)\n",
    "        theta = math.acos(P[2]/r) * 180 / math.pi\n",
    "        phi = math.atan(P[1]/P[0]) * 180 / math.pi\n",
    "        pitch.append(theta)\n",
    "        planes.append(P)\n",
    "        centers.append(ctr)\n",
    "    return np.mean(centers, axis = 0), np.mean(planes, axis = 0), np.mean(pitch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obstacle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import os, os.path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def get_obstacles_with_plane(depth_frame, num_planes, num_points, dist_thresh, visualize):\n",
    "    obstacles = np.zeros(depth_frame.shape) #empty image that will store the locations of detected obstacles\n",
    "    img = np.uint8(depth_frame) #some opencv functions require a byte image\n",
    "\n",
    "    xyz_arr = depthMatrixToPointCloudPos(depth_frame) #convert depth data to XYZ coordinates\n",
    "    start_time = time.time()\n",
    "    center, plane, theta = get_orientation(xyz_arr, num_points)\n",
    "    CameraPosition['elevation'] = -theta\n",
    "    center = applyCameraOrientation(center)\n",
    "    plane = applyCameraOrientation(plane)\n",
    "    xyz_arr = applyCameraMatrixOrientation(xyz_arr)\n",
    "    plane_img = np.zeros(len(xyz_arr))\n",
    "    plane_img[xyz_arr[:,2] > dist_thresh - center[2]] = 1\n",
    "    if visualize:\n",
    "        xyz_arr = xyz_arr[xyz_arr[:,2] > dist_thresh - center[2]]\n",
    "        points = pd.DataFrame(xyz_arr, columns=['x', 'y', 'z']) #convert XYZ coordinates to a DataFrame for pyntcloud\n",
    "        cloud = PyntCloud(points)\n",
    "\n",
    "        lines = [\n",
    "            {\n",
    "                # X axis\n",
    "                \"color\": \"red\", \n",
    "                \"vertices\": [[0, 0, 0], [10, 0, 0]]\n",
    "            },\n",
    "            {\n",
    "                # Y axis\n",
    "                \"color\": \"green\",\n",
    "                \"vertices\": [[0, 0, 0], [0, 10, 0]]\n",
    "            },\n",
    "            {\n",
    "                # Z axis\n",
    "                \"color\": \"blue\",\n",
    "                \"vertices\": [[0, 0, 0], [0, 0, 10]]\n",
    "            },\n",
    "            {\n",
    "                #Original norm of the plane\n",
    "                \"color\": \"pink\",\n",
    "                \"vertices\": [center.tolist(), plane.tolist()]\n",
    "            }\n",
    "        ]\n",
    "        cloud.plot(cmap=\"cool\", polylines=lines)\n",
    "\n",
    "    plane_img = np.uint8(np.reshape(plane_img,(424,512)) * 255) #reshape to match depth data and convert to uint8\n",
    "    plane_img = np.uint8((np.ones((424,512)) * 255) - plane_img) #invert img so pixel value corresponds to NOT ground plane\n",
    "    ret, plane_img = cv2.threshold(plane_img,0,255,cv2.THRESH_BINARY) #filter points that are probaly not ground plane\n",
    "    plane_img = cv2.subtract(img, plane_img)\n",
    "    \n",
    "    #noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(plane_img ,cv2.MORPH_OPEN, kernel, iterations = 3) #erosion followed by dilation\n",
    "\n",
    "    color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) #BGR image to draw labels on\n",
    "\n",
    "    #begin contour detection\n",
    "    image, contours, hierarchy = cv2.findContours(opening,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    color = cv2.drawContours(color, contours, -1, (0,255,0), 1)\n",
    "    for cntr in contours:\n",
    "        try:\n",
    "            #calculate diamter of equivalent circle\n",
    "            #this measurement is only used for checking if countours fit our bounds\n",
    "            area = cv2.contourArea(cntr)\n",
    "            equi_diameter = np.sqrt(4*area/np.pi)\n",
    "\n",
    "            #Hardcoded Diameter Range in pixels\n",
    "            LOW_DIAMETER_BOUND = 20\n",
    "            HIGH_DIAMETER_BOUND = 150\n",
    "\n",
    "            HIGH_DISTANCE_BOUND = 4500\n",
    "            #Original tolerances were 20 and 150\n",
    "\n",
    "            if(equi_diameter>LOW_DIAMETER_BOUND and equi_diameter<HIGH_DIAMETER_BOUND):\n",
    "                mask = np.zeros_like(img) #mask will contain the fitted and adjusted ellipse of a single obstacle\n",
    "                ellipse = cv2.fitEllipse(cntr)\n",
    "                x,y,obj_length,obj_height = cv2.boundingRect(cntr)\n",
    "                rect = cv2.minAreaRect(cntr)\n",
    "\n",
    "                equi_diameter = obj_length #bounding rectangle gives a better approximation of diameter\n",
    "\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                mask = cv2.ellipse(mask,ellipse,(255,255,255),-1) #draw the fitted ellipse\n",
    "                rows = mask.shape[0]\n",
    "                cols = mask.shape[1]\n",
    "                M = np.float32([[1,0,0],[0,1,equi_diameter/4]]) #shift mask down to match obstacle, not edge\n",
    "                mask = cv2.warpAffine(mask,M,(cols,rows))\n",
    "                mask = cv2.erode(mask, kernel, iterations=3) #erode the mask to remove background points\n",
    "                img_fg = cv2.bitwise_and(depth_frame,depth_frame,mask = mask) #use the mask to isolate original depth values\n",
    "                img_fg = cv2.medianBlur(img_fg,5) #median blur to further remove noise\n",
    "                obstacles = cv2.add(np.float32(img_fg), np.float32(obstacles)) \n",
    "                \n",
    "                mean_val = np.median(img_fg[img_fg.nonzero()]) #compute the non-zero average of obstacle depth values\n",
    "                min_val, distance_to_object, min_loc, max_loc = cv2.minMaxLoc(img_fg)\n",
    "\n",
    "                moment = cv2.moments(cntr) #get the centroid of the obstacle using its moment\n",
    "                cx = int(moment['m10']/moment['m00'])\n",
    "                cy = int(moment['m01']/moment['m00'])\n",
    "\n",
    "                if mean_val < HIGH_DISTANCE_BOUND: #kinect loses accuracy beyond 4.5m\n",
    "                    coords = depthToPointCloudPos(cx, cy, mean_val) #convert obstacle depth to XYZ coordinate\n",
    "\n",
    "                    mm_diameter = (equi_diameter) * (1.0 / CameraParams['fx']) * mean_val #convert pixel diameter to mm\n",
    "\n",
    "                    #begin visualization\n",
    "                    cv2.drawContours(color,[box],0,(0,0,255),1)\n",
    "                    cv2.rectangle(color,(x,y),(x+obj_length,y+obj_height),(0,255,0),2)\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(color, \"x\" + str(coords[0]), (cx,cy+30), font, 0.4, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color, \"y\" + str(coords[1]), (cx,cy+45), font, 0.4, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color, \"z\" + str(mean_val), (cx,cy+60), font, 0.4, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color,\"diameter = \" + str(mm_diameter), (cx,cy + 15), font, 0.4, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        except:\n",
    "            print (\"Failed to process image\")\n",
    "            print (sys.exc_info()[0])\n",
    "            \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Frame took \" + str(elapsed_time) + \" seconds to process\")\n",
    "\n",
    "    cv2.imshow(\"plane\",plane_img)\n",
    "    cv2.imshow(\"img\",depth_frame)\n",
    "    cv2.imshow(\"final\",color)\n",
    "    cv2.imshow(\"sure_bg\",opening)\n",
    "    cv2.imshow(\"obstacles\",obstacles)\n",
    "    key = cv2.waitKey(delay=1)\n",
    "    return color\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr\\Anaconda2\\envs\\py36\\lib\\site-packages\\pythreejs\\traits.py:175: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cb053ee22e4d89a8c6051be4576bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(0.0054974926876575295, 0.48841281082603055, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ae44cb6e3944ee8859de7d160ff845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.24083287935113168, max=2.4083287935113167, step…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.6858265399932861 seconds to process\n"
     ]
    }
   ],
   "source": [
    "img = np.load('kinect_data/116.npy')\n",
    "output = get_obstacles_with_plane(img, num_planes = 46, \n",
    "                                  num_points = 45, \n",
    "                                  dist_thresh = 0.1, \n",
    "                                  visualize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Frame Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The Windows bytes API has been deprecated, use Unicode filenames instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinect_data/0.npy\n",
      "Frame took 0.06995749473571777 seconds to process\n",
      "kinect_data/1.npy\n",
      "Frame took 0.07194018363952637 seconds to process\n",
      "kinect_data/10.npy\n",
      "Frame took 0.06596136093139648 seconds to process\n",
      "kinect_data/100.npy\n",
      "Frame took 0.0859670639038086 seconds to process\n",
      "kinect_data/101.npy\n",
      "Frame took 0.08493208885192871 seconds to process\n",
      "kinect_data/102.npy\n",
      "Frame took 0.07595276832580566 seconds to process\n",
      "kinect_data/103.npy\n",
      "Frame took 0.08395123481750488 seconds to process\n",
      "kinect_data/104.npy\n",
      "Frame took 0.08195304870605469 seconds to process\n",
      "kinect_data/105.npy\n",
      "Frame took 0.08296537399291992 seconds to process\n",
      "kinect_data/106.npy\n",
      "Frame took 0.08494925498962402 seconds to process\n",
      "kinect_data/107.npy\n",
      "Frame took 0.08394265174865723 seconds to process\n",
      "kinect_data/108.npy\n",
      "Frame took 0.08393621444702148 seconds to process\n",
      "kinect_data/109.npy\n",
      "Frame took 0.08494710922241211 seconds to process\n",
      "kinect_data/11.npy\n",
      "Frame took 0.07192826271057129 seconds to process\n",
      "kinect_data/110.npy\n",
      "Frame took 0.08293771743774414 seconds to process\n",
      "kinect_data/111.npy\n",
      "Frame took 0.08493900299072266 seconds to process\n",
      "kinect_data/112.npy\n",
      "Frame took 0.08295130729675293 seconds to process\n",
      "kinect_data/113.npy\n",
      "Frame took 0.08496427536010742 seconds to process\n",
      "kinect_data/114.npy\n",
      "Frame took 0.08293533325195312 seconds to process\n",
      "kinect_data/115.npy\n",
      "Frame took 0.08395123481750488 seconds to process\n",
      "kinect_data/116.npy\n",
      "Frame took 0.0809481143951416 seconds to process\n",
      "kinect_data/117.npy\n",
      "Frame took 0.08391952514648438 seconds to process\n",
      "kinect_data/118.npy\n",
      "Frame took 0.0829472541809082 seconds to process\n",
      "kinect_data/119.npy\n",
      "Frame took 0.08794593811035156 seconds to process\n",
      "kinect_data/12.npy\n",
      "Frame took 0.07993721961975098 seconds to process\n",
      "kinect_data/120.npy\n",
      "Frame took 0.09094715118408203 seconds to process\n",
      "kinect_data/121.npy\n",
      "Frame took 0.08593010902404785 seconds to process\n",
      "kinect_data/122.npy\n",
      "Frame took 0.0779726505279541 seconds to process\n",
      "kinect_data/123.npy\n",
      "Frame took 0.07195663452148438 seconds to process\n",
      "kinect_data/124.npy\n",
      "Frame took 0.0699462890625 seconds to process\n",
      "kinect_data/125.npy\n",
      "Frame took 0.07193946838378906 seconds to process\n",
      "kinect_data/126.npy\n",
      "Frame took 0.09194493293762207 seconds to process\n",
      "kinect_data/127.npy\n",
      "Frame took 0.07495594024658203 seconds to process\n",
      "kinect_data/128.npy\n",
      "Frame took 0.09294629096984863 seconds to process\n",
      "kinect_data/129.npy\n",
      "Frame took 0.08295226097106934 seconds to process\n",
      "kinect_data/13.npy\n",
      "Frame took 0.07493948936462402 seconds to process\n",
      "kinect_data/130.npy\n",
      "Frame took 0.07295751571655273 seconds to process\n",
      "kinect_data/131.npy\n",
      "Frame took 0.09394645690917969 seconds to process\n",
      "kinect_data/132.npy\n",
      "Frame took 0.08994770050048828 seconds to process\n",
      "kinect_data/133.npy\n",
      "Frame took 0.08694696426391602 seconds to process\n",
      "kinect_data/134.npy\n",
      "Frame took 0.09393787384033203 seconds to process\n",
      "kinect_data/135.npy\n",
      "Frame took 0.08393502235412598 seconds to process\n",
      "kinect_data/136.npy\n",
      "Frame took 0.08193159103393555 seconds to process\n",
      "kinect_data/137.npy\n",
      "Frame took 0.08093452453613281 seconds to process\n",
      "kinect_data/138.npy\n",
      "Frame took 0.07896661758422852 seconds to process\n",
      "kinect_data/139.npy\n",
      "Frame took 0.07695341110229492 seconds to process\n",
      "kinect_data/14.npy\n",
      "Frame took 0.06995964050292969 seconds to process\n",
      "kinect_data/140.npy\n",
      "Frame took 0.08195185661315918 seconds to process\n",
      "kinect_data/141.npy\n",
      "Frame took 0.0779721736907959 seconds to process\n",
      "kinect_data/142.npy\n",
      "Frame took 0.075958251953125 seconds to process\n",
      "kinect_data/143.npy\n",
      "Frame took 0.07495498657226562 seconds to process\n",
      "kinect_data/144.npy\n",
      "Frame took 0.07593774795532227 seconds to process\n",
      "kinect_data/145.npy\n",
      "Frame took 0.0789487361907959 seconds to process\n",
      "kinect_data/146.npy\n",
      "Frame took 0.0759737491607666 seconds to process\n",
      "kinect_data/147.npy\n",
      "Frame took 0.08095264434814453 seconds to process\n",
      "kinect_data/148.npy\n",
      "Frame took 0.08393144607543945 seconds to process\n",
      "kinect_data/149.npy\n",
      "Frame took 0.08792924880981445 seconds to process\n",
      "kinect_data/15.npy\n",
      "Frame took 0.07195544242858887 seconds to process\n",
      "kinect_data/150.npy\n",
      "Frame took 0.08994197845458984 seconds to process\n",
      "kinect_data/151.npy\n",
      "Frame took 0.09394550323486328 seconds to process\n",
      "kinect_data/152.npy\n",
      "Frame took 0.08994603157043457 seconds to process\n",
      "kinect_data/153.npy\n",
      "Frame took 0.07893490791320801 seconds to process\n",
      "kinect_data/154.npy\n",
      "Frame took 0.07993578910827637 seconds to process\n",
      "kinect_data/155.npy\n",
      "Frame took 0.07495665550231934 seconds to process\n",
      "kinect_data/156.npy\n",
      "Frame took 0.07395720481872559 seconds to process\n",
      "kinect_data/157.npy\n",
      "Frame took 0.07896685600280762 seconds to process\n",
      "kinect_data/158.npy\n",
      "Frame took 0.07695579528808594 seconds to process\n",
      "kinect_data/159.npy\n",
      "Frame took 0.07395744323730469 seconds to process\n",
      "kinect_data/16.npy\n",
      "Frame took 0.07895493507385254 seconds to process\n",
      "kinect_data/160.npy\n",
      "Frame took 0.07195520401000977 seconds to process\n",
      "kinect_data/161.npy\n",
      "Frame took 0.07495975494384766 seconds to process\n",
      "kinect_data/162.npy\n",
      "Frame took 0.07395648956298828 seconds to process\n",
      "kinect_data/163.npy\n",
      "Frame took 0.07293987274169922 seconds to process\n",
      "kinect_data/164.npy\n",
      "Frame took 0.07894730567932129 seconds to process\n",
      "kinect_data/165.npy\n",
      "Frame took 0.07397270202636719 seconds to process\n",
      "kinect_data/166.npy\n",
      "Frame took 0.07995367050170898 seconds to process\n",
      "kinect_data/167.npy\n",
      "Frame took 0.0829324722290039 seconds to process\n",
      "kinect_data/168.npy\n",
      "Frame took 0.085968017578125 seconds to process\n",
      "kinect_data/169.npy\n",
      "Frame took 0.07995247840881348 seconds to process\n",
      "kinect_data/17.npy\n",
      "Frame took 0.07095932960510254 seconds to process\n",
      "kinect_data/170.npy\n",
      "Frame took 0.0789484977722168 seconds to process\n",
      "kinect_data/171.npy\n",
      "Frame took 0.07993531227111816 seconds to process\n",
      "kinect_data/172.npy\n",
      "Frame took 0.07895064353942871 seconds to process\n",
      "kinect_data/173.npy\n",
      "Frame took 0.07895231246948242 seconds to process\n",
      "kinect_data/174.npy\n",
      "Frame took 0.07995176315307617 seconds to process\n",
      "kinect_data/175.npy\n",
      "Frame took 0.07593750953674316 seconds to process\n",
      "kinect_data/176.npy\n",
      "Frame took 0.07297611236572266 seconds to process\n",
      "kinect_data/177.npy\n",
      "Frame took 0.0769350528717041 seconds to process\n",
      "kinect_data/178.npy\n",
      "Frame took 0.08095335960388184 seconds to process\n",
      "kinect_data/179.npy\n",
      "Frame took 0.07893514633178711 seconds to process\n",
      "kinect_data/18.npy\n",
      "Frame took 0.0699455738067627 seconds to process\n",
      "kinect_data/180.npy\n",
      "Frame took 0.07893538475036621 seconds to process\n",
      "kinect_data/181.npy\n",
      "Frame took 0.07595610618591309 seconds to process\n",
      "kinect_data/182.npy\n",
      "Frame took 0.07393908500671387 seconds to process\n",
      "kinect_data/183.npy\n",
      "Frame took 0.07895421981811523 seconds to process\n",
      "kinect_data/184.npy\n",
      "Frame took 0.07393813133239746 seconds to process\n",
      "kinect_data/185.npy\n",
      "Frame took 0.07893729209899902 seconds to process\n",
      "kinect_data/186.npy\n",
      "Frame took 0.08694672584533691 seconds to process\n",
      "kinect_data/187.npy\n",
      "Frame took 0.07793855667114258 seconds to process\n",
      "kinect_data/188.npy\n",
      "Frame took 0.07294964790344238 seconds to process\n",
      "kinect_data/189.npy\n",
      "Frame took 0.08395242691040039 seconds to process\n",
      "kinect_data/19.npy\n",
      "Frame took 0.07193613052368164 seconds to process\n",
      "kinect_data/190.npy\n",
      "Frame took 0.07996463775634766 seconds to process\n",
      "kinect_data/191.npy\n",
      "Frame took 0.08896374702453613 seconds to process\n",
      "kinect_data/192.npy\n",
      "Frame took 0.07295727729797363 seconds to process\n",
      "kinect_data/193.npy\n",
      "Frame took 0.07595586776733398 seconds to process\n",
      "kinect_data/194.npy\n",
      "Frame took 0.07295775413513184 seconds to process\n",
      "kinect_data/195.npy\n",
      "Frame took 0.07194209098815918 seconds to process\n",
      "kinect_data/196.npy\n",
      "Frame took 0.0849459171295166 seconds to process\n",
      "kinect_data/197.npy\n",
      "Frame took 0.08293581008911133 seconds to process\n",
      "kinect_data/198.npy\n",
      "Frame took 0.07295680046081543 seconds to process\n",
      "kinect_data/199.npy\n",
      "Frame took 0.08196640014648438 seconds to process\n",
      "kinect_data/2.npy\n",
      "Frame took 0.06794285774230957 seconds to process\n",
      "kinect_data/20.npy\n",
      "Frame took 0.07193875312805176 seconds to process\n",
      "kinect_data/200.npy\n",
      "Frame took 0.07695460319519043 seconds to process\n",
      "kinect_data/201.npy\n",
      "Frame took 0.08095240592956543 seconds to process\n",
      "kinect_data/202.npy\n",
      "Frame took 0.0839543342590332 seconds to process\n",
      "kinect_data/203.npy\n",
      "Frame took 0.07595372200012207 seconds to process\n",
      "kinect_data/204.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.07595562934875488 seconds to process\n",
      "kinect_data/205.npy\n",
      "Frame took 0.06496214866638184 seconds to process\n",
      "kinect_data/206.npy\n",
      "Frame took 0.06997156143188477 seconds to process\n",
      "kinect_data/207.npy\n",
      "Frame took 0.06894111633300781 seconds to process\n",
      "kinect_data/208.npy\n",
      "Frame took 0.06894373893737793 seconds to process\n",
      "kinect_data/209.npy\n",
      "Frame took 0.07294201850891113 seconds to process\n",
      "kinect_data/21.npy\n",
      "Frame took 0.07193922996520996 seconds to process\n",
      "kinect_data/210.npy\n",
      "Frame took 0.06895852088928223 seconds to process\n",
      "kinect_data/211.npy\n",
      "Frame took 0.06894063949584961 seconds to process\n",
      "kinect_data/212.npy\n",
      "Frame took 0.07096362113952637 seconds to process\n",
      "kinect_data/213.npy\n",
      "Frame took 0.06894183158874512 seconds to process\n",
      "kinect_data/214.npy\n",
      "Frame took 0.06897830963134766 seconds to process\n",
      "kinect_data/215.npy\n",
      "Frame took 0.06796073913574219 seconds to process\n",
      "kinect_data/216.npy\n",
      "Frame took 0.07295513153076172 seconds to process\n",
      "kinect_data/217.npy\n",
      "Frame took 0.06994128227233887 seconds to process\n",
      "kinect_data/218.npy\n",
      "Frame took 0.0679621696472168 seconds to process\n",
      "kinect_data/219.npy\n",
      "Frame took 0.07393932342529297 seconds to process\n",
      "kinect_data/22.npy\n",
      "Frame took 0.0859689712524414 seconds to process\n",
      "kinect_data/220.npy\n",
      "Frame took 0.06894993782043457 seconds to process\n",
      "kinect_data/221.npy\n",
      "Frame took 0.06696009635925293 seconds to process\n",
      "kinect_data/222.npy\n",
      "Frame took 0.07195806503295898 seconds to process\n",
      "kinect_data/223.npy\n",
      "Frame took 0.0729374885559082 seconds to process\n",
      "kinect_data/224.npy\n",
      "Frame took 0.06896424293518066 seconds to process\n",
      "kinect_data/225.npy\n",
      "Frame took 0.07095718383789062 seconds to process\n",
      "kinect_data/226.npy\n",
      "Frame took 0.07693886756896973 seconds to process\n",
      "kinect_data/227.npy\n",
      "Frame took 0.07093930244445801 seconds to process\n",
      "kinect_data/228.npy\n",
      "Frame took 0.07098960876464844 seconds to process\n",
      "kinect_data/229.npy\n",
      "Frame took 0.06895995140075684 seconds to process\n",
      "kinect_data/23.npy\n",
      "Frame took 0.08495068550109863 seconds to process\n",
      "kinect_data/24.npy\n",
      "Frame took 0.08394551277160645 seconds to process\n",
      "kinect_data/25.npy\n",
      "Frame took 0.07593727111816406 seconds to process\n",
      "kinect_data/26.npy\n",
      "Frame took 0.07995367050170898 seconds to process\n",
      "kinect_data/27.npy\n",
      "Frame took 0.07895398139953613 seconds to process\n",
      "kinect_data/28.npy\n",
      "Frame took 0.08294868469238281 seconds to process\n",
      "kinect_data/29.npy\n",
      "Frame took 0.07695555686950684 seconds to process\n",
      "kinect_data/3.npy\n",
      "Frame took 0.0699770450592041 seconds to process\n",
      "kinect_data/30.npy\n",
      "Frame took 0.0809483528137207 seconds to process\n",
      "kinect_data/31.npy\n",
      "Frame took 0.07693648338317871 seconds to process\n",
      "kinect_data/32.npy\n",
      "Frame took 0.08196616172790527 seconds to process\n",
      "kinect_data/33.npy\n",
      "Frame took 0.0809326171875 seconds to process\n",
      "kinect_data/34.npy\n",
      "Frame took 0.0809469223022461 seconds to process\n",
      "kinect_data/35.npy\n",
      "Frame took 0.0749368667602539 seconds to process\n",
      "kinect_data/36.npy\n",
      "Frame took 0.08495044708251953 seconds to process\n",
      "kinect_data/37.npy\n",
      "Frame took 0.07395744323730469 seconds to process\n",
      "kinect_data/38.npy\n",
      "Frame took 0.08295178413391113 seconds to process\n",
      "kinect_data/39.npy\n",
      "Frame took 0.0889432430267334 seconds to process\n",
      "kinect_data/4.npy\n",
      "Frame took 0.07093977928161621 seconds to process\n",
      "kinect_data/40.npy\n",
      "Frame took 0.09394979476928711 seconds to process\n",
      "kinect_data/41.npy\n",
      "Frame took 0.08794784545898438 seconds to process\n",
      "kinect_data/42.npy\n",
      "Frame took 0.09593939781188965 seconds to process\n",
      "kinect_data/43.npy\n",
      "Frame took 0.07593750953674316 seconds to process\n",
      "kinect_data/44.npy\n",
      "Frame took 0.08794832229614258 seconds to process\n",
      "kinect_data/45.npy\n",
      "Frame took 0.07793498039245605 seconds to process\n",
      "kinect_data/46.npy\n",
      "Frame took 0.0789341926574707 seconds to process\n",
      "kinect_data/47.npy\n",
      "Frame took 0.08396434783935547 seconds to process\n",
      "kinect_data/48.npy\n",
      "Frame took 0.09292960166931152 seconds to process\n",
      "kinect_data/49.npy\n",
      "Frame took 0.0749366283416748 seconds to process\n",
      "kinect_data/5.npy\n",
      "Frame took 0.06894040107727051 seconds to process\n",
      "kinect_data/50.npy\n",
      "Frame took 0.08894872665405273 seconds to process\n",
      "kinect_data/51.npy\n",
      "Frame took 0.08194828033447266 seconds to process\n",
      "kinect_data/52.npy\n",
      "Frame took 0.0849602222442627 seconds to process\n",
      "kinect_data/53.npy\n",
      "Frame took 0.09092402458190918 seconds to process\n",
      "kinect_data/54.npy\n",
      "Frame took 0.0849454402923584 seconds to process\n",
      "kinect_data/55.npy\n",
      "Frame took 0.0819711685180664 seconds to process\n",
      "kinect_data/56.npy\n",
      "Frame took 0.09194445610046387 seconds to process\n",
      "kinect_data/57.npy\n",
      "Frame took 0.0879371166229248 seconds to process\n",
      "kinect_data/58.npy\n",
      "Frame took 0.08194732666015625 seconds to process\n",
      "kinect_data/59.npy\n",
      "Frame took 0.0949404239654541 seconds to process\n",
      "kinect_data/6.npy\n",
      "Frame took 0.07195591926574707 seconds to process\n",
      "kinect_data/60.npy\n",
      "Frame took 0.08394598960876465 seconds to process\n",
      "kinect_data/61.npy\n",
      "Frame took 0.0869600772857666 seconds to process\n",
      "kinect_data/62.npy\n",
      "Frame took 0.08195161819458008 seconds to process\n",
      "kinect_data/63.npy\n",
      "Frame took 0.07195520401000977 seconds to process\n",
      "kinect_data/64.npy\n",
      "Frame took 0.07494688034057617 seconds to process\n",
      "kinect_data/65.npy\n",
      "Frame took 0.08593130111694336 seconds to process\n",
      "kinect_data/66.npy\n",
      "Frame took 0.07495737075805664 seconds to process\n",
      "kinect_data/67.npy\n",
      "Frame took 0.07194209098815918 seconds to process\n",
      "kinect_data/68.npy\n",
      "Frame took 0.08093738555908203 seconds to process\n",
      "kinect_data/69.npy\n",
      "Frame took 0.07195901870727539 seconds to process\n",
      "kinect_data/7.npy\n",
      "Frame took 0.07795548439025879 seconds to process\n",
      "kinect_data/70.npy\n",
      "Frame took 0.07195758819580078 seconds to process\n",
      "kinect_data/71.npy\n",
      "Frame took 0.07095623016357422 seconds to process\n",
      "kinect_data/72.npy\n",
      "Frame took 0.08293366432189941 seconds to process\n",
      "kinect_data/73.npy\n",
      "Frame took 0.07293987274169922 seconds to process\n",
      "kinect_data/74.npy\n",
      "Frame took 0.07697200775146484 seconds to process\n",
      "kinect_data/75.npy\n",
      "Frame took 0.07396054267883301 seconds to process\n",
      "kinect_data/76.npy\n",
      "Frame took 0.07295751571655273 seconds to process\n",
      "kinect_data/77.npy\n",
      "Frame took 0.07293438911437988 seconds to process\n",
      "kinect_data/78.npy\n",
      "Frame took 0.07293915748596191 seconds to process\n",
      "kinect_data/79.npy\n",
      "Frame took 0.0719609260559082 seconds to process\n",
      "kinect_data/8.npy\n",
      "Frame took 0.07096600532531738 seconds to process\n",
      "kinect_data/80.npy\n",
      "Frame took 0.07394528388977051 seconds to process\n",
      "kinect_data/81.npy\n",
      "Frame took 0.07994985580444336 seconds to process\n",
      "kinect_data/82.npy\n",
      "Frame took 0.07494044303894043 seconds to process\n",
      "kinect_data/83.npy\n",
      "Frame took 0.08992981910705566 seconds to process\n",
      "kinect_data/84.npy\n",
      "Frame took 0.07895421981811523 seconds to process\n",
      "kinect_data/85.npy\n",
      "Frame took 0.08193492889404297 seconds to process\n",
      "kinect_data/86.npy\n",
      "Frame took 0.08293390274047852 seconds to process\n",
      "kinect_data/87.npy\n",
      "Frame took 0.09594416618347168 seconds to process\n",
      "kinect_data/88.npy\n",
      "Frame took 0.07693338394165039 seconds to process\n",
      "kinect_data/89.npy\n",
      "Frame took 0.0969386100769043 seconds to process\n",
      "kinect_data/9.npy\n",
      "Frame took 0.07393956184387207 seconds to process\n",
      "kinect_data/90.npy\n",
      "Frame took 0.09194660186767578 seconds to process\n",
      "kinect_data/91.npy\n",
      "Frame took 0.08393359184265137 seconds to process\n",
      "kinect_data/92.npy\n",
      "Frame took 0.08594870567321777 seconds to process\n",
      "kinect_data/93.npy\n",
      "Frame took 0.08292055130004883 seconds to process\n",
      "kinect_data/94.npy\n",
      "Frame took 0.08596324920654297 seconds to process\n",
      "kinect_data/95.npy\n",
      "Frame took 0.09294342994689941 seconds to process\n",
      "kinect_data/96.npy\n",
      "Frame took 0.0849459171295166 seconds to process\n",
      "kinect_data/97.npy\n",
      "Frame took 0.08794856071472168 seconds to process\n",
      "kinect_data/98.npy\n",
      "Frame took 0.08395123481750488 seconds to process\n",
      "kinect_data/99.npy\n",
      "Frame took 0.0849313735961914 seconds to process\n"
     ]
    }
   ],
   "source": [
    "frames_dir = 'kinect_data/'\n",
    "directory = os.fsencode(frames_dir)\n",
    "frame_i = 0\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".npy\"):\n",
    "        file_path = frames_dir + filename\n",
    "        print(file_path)\n",
    "        img = np.load(file_path)\n",
    "        try:\n",
    "            output = get_obstacles_with_plane(img, num_planes = 46, \n",
    "                                  num_points = 45, \n",
    "                                  dist_thresh = 0.1, \n",
    "                                  visualize = False)\n",
    "            cv2.imwrite(os.path.join(path ,filename[:-4] + '.png'), output)\n",
    "            frame_i += 1\n",
    "        except:\n",
    "            print(\"Could not find obstacles\")\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
