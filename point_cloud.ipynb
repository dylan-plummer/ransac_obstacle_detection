{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import os, os.path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "frames_dir = \"kinect_data/\"\n",
    "\n",
    "#camera information based on the Kinect v2 hardware\n",
    "CameraParams = {\n",
    "  \"cx\":254.878,\n",
    "  \"cy\":205.395,\n",
    "  \"fx\":365.456,\n",
    "  \"fy\":365.456,\n",
    "  \"k1\":0.0905474,\n",
    "  \"k2\":-0.26819,\n",
    "  \"k3\":0.0950862,\n",
    "  \"p1\":0.0,\n",
    "  \"p2\":0.0,\n",
    "}\n",
    "\n",
    "# Kinect's physical orientation in the real world.\n",
    "CameraPosition = {\n",
    "    \"x\": 0, # actual position in meters of kinect sensor relative to the viewport's center.\n",
    "    \"y\": 0, # actual position in meters of kinect sensor relative to the viewport's center.\n",
    "    \"z\": 0, # height in meters of actual kinect sensor from the floor.\n",
    "    \"roll\": 0, # angle in degrees of sensor's roll (used for INU input - trig function for this is commented out by default).\n",
    "    \"azimuth\": 0, # sensor's yaw angle in degrees.\n",
    "    \"elevation\": -30, # sensor's pitch angle in degrees.\n",
    "}\n",
    "\n",
    "def depthMatrixToPointCloudPos(z, scale=1000):\n",
    "    #bacically this is a vectorized version of depthToPointCloudPos()\n",
    "    C, R = np.indices(z.shape)\n",
    "\n",
    "    R = np.subtract(R, CameraParams['cx'])\n",
    "    R = np.multiply(R, z)\n",
    "    R = np.divide(R, CameraParams['fx'] * scale)\n",
    "\n",
    "    C = np.subtract(C, CameraParams['cy'])\n",
    "    C = np.multiply(C, z)\n",
    "    C = np.divide(C, CameraParams['fy'] * scale)\n",
    "\n",
    "    return np.column_stack((z.ravel() / scale, R.ravel(), -C.ravel()))\n",
    "\n",
    "def depthToPointCloudPos(x_d, y_d, z, scale=1000):\n",
    "    # This runs in Python slowly as it is required to be called from within a loop, but it is a more intuitive example than it's vertorized alternative (Purly for example)\n",
    "    # calculate the real-world xyz vertex coordinate from the raw depth data (one vertex at a time).\n",
    "    x = (x_d - CameraParams['cx']) * z / CameraParams['fx']\n",
    "    y = (y_d - CameraParams['cy']) * z / CameraParams['fy']\n",
    "\n",
    "    return x / scale, y / scale, z / scale\n",
    "\n",
    "def applyCameraOrientation(pt):\n",
    "    # Kinect Sensor Orientation Compensation\n",
    "    # This runs slowly in Python as it is required to be called within a loop, but it is a more intuitive example than it's vertorized alternative (Purly for example)\n",
    "    # use trig to rotate a vertex around a gimbal.\n",
    "    def rotatePoints(ax1, ax2, deg):\n",
    "        # math to rotate vertexes around a center point on a plane.\n",
    "        hyp = np.sqrt(pt[ax1] ** 2 + pt[ax2] ** 2) # Get the length of the hypotenuse of the real-world coordinate from center of rotation, this is the radius!\n",
    "        d_tan = np.arctan2(pt[ax2], pt[ax1]) # Calculate the vertexes current angle (returns radians that go from -180 to 180)\n",
    "\n",
    "        cur_angle = np.degrees(d_tan) % 360 # Convert radians to degrees and use modulo to adjust range from 0 to 360.\n",
    "        new_angle = np.radians((cur_angle + deg) % 360) # The new angle (in radians) of the vertexes after being rotated by the value of deg.\n",
    "\n",
    "        pt[ax1] = hyp * np.cos(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "        pt[ax2] = hyp * np.sin(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "\n",
    "    #rotatePoints(0, 2, CameraPosition['roll']) #rotate on the Y&Z plane # Disabled because most tripods don't roll. If an Inertial Nav Unit is available this could be used)\n",
    "    rotatePoints(1, 2, CameraPosition['elevation']) #rotate on the X&Z plane\n",
    "    rotatePoints(0, 1, CameraPosition['azimuth']) #rotate on the X&Y plane\n",
    "\n",
    "    # Apply offsets for height and linear position of the sensor (from viewport's center)\n",
    "    pt[:] += np.float_([CameraPosition['x'], CameraPosition['y'], CameraPosition['z']])\n",
    "    return pt\n",
    "\n",
    "def applyCameraMatrixOrientation(pt):\n",
    "    # Kinect Sensor Orientation Compensation\n",
    "    # bacically this is a vectorized version of applyCameraOrientation()\n",
    "    # uses same trig to rotate a vertex around a gimbal.\n",
    "    def rotatePoints(ax1, ax2, deg):\n",
    "        # math to rotate vertexes around a center point on a plane.\n",
    "        hyp = np.sqrt(pt[:, ax1] ** 2 + pt[:, ax2] ** 2) # Get the length of the hypotenuse of the real-world coordinate from center of rotation, this is the radius!\n",
    "        d_tan = np.arctan2(pt[:, ax2], pt[:, ax1]) # Calculate the vertexes current angle (returns radians that go from -180 to 180)\n",
    "\n",
    "        cur_angle = np.degrees(d_tan) % 360 # Convert radians to degrees and use modulo to adjust range from 0 to 360.\n",
    "        new_angle = np.radians((cur_angle + deg) % 360) # The new angle (in radians) of the vertexes after being rotated by the value of deg.\n",
    "\n",
    "        pt[:, ax1] = hyp * np.cos(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "        pt[:, ax2] = hyp * np.sin(new_angle) # Calculate the rotated coordinate for this axis.\n",
    "\n",
    "    #rotatePoints(1, 2, CameraPosition['roll']) #rotate on the Y&Z plane # Disabled because most tripods don't roll. If an Inertial Nav Unit is available this could be used)\n",
    "    rotatePoints(0, 2, CameraPosition['elevation']) #rotate on the X&Z plane\n",
    "    rotatePoints(0, 1, CameraPosition['azimuth']) #rotate on the X&Y\n",
    "\n",
    "    # Apply offsets for height and linear position of the sensor (from viewport's center)\n",
    "    pt[:] += np.float_([CameraPosition['x'], CameraPosition['y'], CameraPosition['z']])\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plane_fit(points):\n",
    "    \"\"\"\n",
    "    p, n = planeFit(points)\n",
    "\n",
    "    Given an array, points, of shape (d,...)\n",
    "    representing points in d-dimensional space,\n",
    "    fit an d-dimensional plane to the points.\n",
    "    Return a point, p, on the plane (the point-cloud centroid),\n",
    "    and the normal, n.\n",
    "    \"\"\"\n",
    "    from numpy.linalg import svd\n",
    "    points = np.reshape(points, (np.shape(points)[0], -1)) # Collapse trialing dimensions\n",
    "    assert points.shape[0] <= points.shape[1], \"There are only {} points in {} dimensions.\".format(points.shape[1], points.shape[0])\n",
    "    ctr = points.mean(axis=1)\n",
    "    x = points - ctr[:,np.newaxis]\n",
    "    M = np.dot(x, x.T) # Could also use np.cov(x) here.\n",
    "    return ctr, svd(M)[0][:,-1]\n",
    "\n",
    "def get_orientation(xyz_arr, n_iter):\n",
    "    spherical = []\n",
    "    planes = []\n",
    "    centers = []\n",
    "    for _ in range(0, n_iter):\n",
    "        rand_points = []\n",
    "        while len(rand_points) < 10:\n",
    "            index = random.randrange(0,len(xyz_arr))\n",
    "            if not xyz_arr[index].all() == np.zeros(3).all():\n",
    "                rand_points.append(xyz_arr[index])\n",
    "        rand_points = np.array(rand_points).T\n",
    "        ctr, P = plane_fit(rand_points)\n",
    "        r = math.sqrt(P[0]**2 + P[1]**2 + P[2]**2)\n",
    "        theta = math.acos(P[2]/r) * 180 / math.pi\n",
    "        phi = math.atan(P[1]/P[0]) * 180 / math.pi\n",
    "        spherical.append(theta)\n",
    "        planes.append(P)\n",
    "        centers.append(ctr)\n",
    "    return np.mean(centers, axis = 0), np.mean(planes, axis = 0), np.mean(spherical)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "import os, os.path\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def get_obstacles_with_plane(depth_frame, num_planes, num_points, dist_thresh, visualize):\n",
    "    obstacles = np.zeros(depth_frame.shape) #empty image that will store the locations of detected obstacles\n",
    "    img = np.uint8(depth_frame) #some opencv functions break when you pass a float array\n",
    "\n",
    "    xyz_arr = depthMatrixToPointCloudPos(depth_frame) #convert depth data to XYZ coordinates\n",
    "    start_time = time.time()\n",
    "    center, plane, theta = get_orientation(xyz_arr, num_points)\n",
    "    CameraPosition['elevation'] = -theta\n",
    "    center = applyCameraOrientation(center)\n",
    "    plane = applyCameraOrientation(plane)\n",
    "    xyz_arr = applyCameraMatrixOrientation(xyz_arr)\n",
    "    plane_img = np.zeros(len(xyz_arr))\n",
    "    plane_img[xyz_arr[:,2] > dist_thresh - center[2]] = 1\n",
    "    if visualize:\n",
    "        xyz_arr = xyz_arr[xyz_arr[:,2] > dist_thresh - center[2]]\n",
    "        points = pd.DataFrame(xyz_arr, columns=['x', 'y', 'z']) #convert XYZ coordinates to a DataFrame for pyntcloud\n",
    "        cloud = PyntCloud(points)\n",
    "\n",
    "        lines = [\n",
    "            {\n",
    "                \"color\": \"red\",\n",
    "                \"vertices\": [[0, 0, 0], [10, 0, 0]]\n",
    "            },\n",
    "            {\n",
    "                \"color\": \"green\",\n",
    "                \"vertices\": [[0, 0, 0], [0, 10, 0]]\n",
    "            },\n",
    "            {\n",
    "                \"color\": \"blue\",\n",
    "                \"vertices\": [[0, 0, 0], [0, 0, 10]]\n",
    "            },\n",
    "            {\n",
    "                \"color\": \"pink\",\n",
    "                \"vertices\": [center.tolist(), plane.tolist()]\n",
    "            }\n",
    "        ]\n",
    "        cloud.plot(cmap=\"cool\", polylines=lines)\n",
    "\n",
    "    plane_img = np.uint8(np.reshape(plane_img,(424,512)) * 255) #reshape to match depth data and convert to uint8\n",
    "    plane_img = np.uint8((np.ones((424,512)) * 255) - plane_img) #invert img so pixel value corresponds to NOT ground plane\n",
    "    ret, plane_img = cv2.threshold(plane_img,0,255,cv2.THRESH_BINARY) #filter points that are probaly not ground plane\n",
    "    plane_img = cv2.subtract(img, plane_img)\n",
    "    \n",
    "    #noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(plane_img ,cv2.MORPH_OPEN, kernel, iterations = 3) #erosion followed by dilation\n",
    "\n",
    "    color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) #BGR image to draw labels on\n",
    "\n",
    "    #begin contour detection\n",
    "    image, contours, hierarchy = cv2.findContours(opening,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    color = cv2.drawContours(color, contours, -1, (0,255,0), 1)\n",
    "    for cntr in contours:\n",
    "        try:\n",
    "            #calculate diamter of equivalent circle\n",
    "            #this measurement is only used for checking if countours fit our bounds\n",
    "            area = cv2.contourArea(cntr)\n",
    "            equi_diameter = np.sqrt(4*area/np.pi)\n",
    "\n",
    "            #Hardcoded Diameter Range in pixels\n",
    "            LOW_DIAMETER_BOUND = 20\n",
    "            HIGH_DIAMETER_BOUND = 150\n",
    "\n",
    "            HIGH_DISTANCE_BOUND = 4500\n",
    "            #Original tolerances were 20 and 150\n",
    "\n",
    "            if(equi_diameter>LOW_DIAMETER_BOUND and equi_diameter<HIGH_DIAMETER_BOUND):\n",
    "                mask = np.zeros_like(img) #mask will contain the fitted and adjusted ellipse of a single obstacle\n",
    "                ellipse = cv2.fitEllipse(cntr)\n",
    "                x,y,obj_length,obj_height = cv2.boundingRect(cntr)\n",
    "                rect = cv2.minAreaRect(cntr)\n",
    "\n",
    "                equi_diameter = obj_length #bounding rectangle gives a better approximation of diameter\n",
    "\n",
    "                box = cv2.boxPoints(rect)\n",
    "                box = np.int0(box)\n",
    "                mask = cv2.ellipse(mask,ellipse,(255,255,255),-1) #draw the fitted ellipse\n",
    "                rows = mask.shape[0]\n",
    "                cols = mask.shape[1]\n",
    "                M = np.float32([[1,0,0],[0,1,equi_diameter/4]]) #shift mask down to match obstacle, not edge\n",
    "                mask = cv2.warpAffine(mask,M,(cols,rows))\n",
    "                mask = cv2.erode(mask, kernel, iterations=3) #erode the mask to remove background points\n",
    "                img_fg = cv2.bitwise_and(depth_frame,depth_frame,mask = mask) #use the mask to isolate original depth values\n",
    "                img_fg = cv2.medianBlur(img_fg,5) #median blur to further remove noise\n",
    "                obstacles = cv2.add(np.float32(img_fg), np.float32(obstacles)) \n",
    "                \n",
    "                mean_val = np.median(img_fg[img_fg.nonzero()]) #compute the non-zero average of obstacle depth values\n",
    "                min_val, distance_to_object, min_loc, max_loc = cv2.minMaxLoc(img_fg)\n",
    "\n",
    "                moment = cv2.moments(cntr) #get the centroid of the obstacle using its moment\n",
    "                cx = int(moment['m10']/moment['m00'])\n",
    "                cy = int(moment['m01']/moment['m00'])\n",
    "\n",
    "                if mean_val < HIGH_DISTANCE_BOUND: #kinect loses accuracy beyond 4.5m\n",
    "                    coords = depthToPointCloudPos(cx, cy, mean_val) #convert obstacle depth to XYZ coordinate\n",
    "\n",
    "                    mm_diameter = (equi_diameter) * (1.0 / CameraParams['fx']) * mean_val #convert pixel diameter to mm\n",
    "\n",
    "                    #begin visualization\n",
    "                    cv2.drawContours(color,[box],0,(0,0,255),1)\n",
    "                    cv2.rectangle(color,(x,y),(x+obj_length,y+obj_height),(0,255,0),2)\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cv2.putText(color, \"x\" + str(coords[0]), (cx,cy+30), font, 0.4, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color, \"y\" + str(coords[1]), (cx,cy+45), font, 0.4, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color, \"z\" + str(mean_val), (cx,cy+60), font, 0.4, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.putText(color,\"diameter = \" + str(mm_diameter), (cx,cy + 15), font, 0.4, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "        except:\n",
    "            print (\"Failed to process image\")\n",
    "            print (sys.exc_info()[0])\n",
    "            \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Frame took \" + str(elapsed_time) + \" seconds to process\")\n",
    "\n",
    "    cv2.imshow(\"plane\",plane_img)\n",
    "    cv2.imshow(\"img\",depth_frame)\n",
    "    cv2.imshow(\"final\",color)\n",
    "    cv2.imshow(\"sure_bg\",opening)\n",
    "    cv2.imshow(\"obstacles\",obstacles)\n",
    "    key = cv2.waitKey(delay=1)\n",
    "    return color\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\pythreejs\\traits.py:175: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f41a72ed4b4136875516f2f3285914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(0.007798590999836477, 0.4945696268146172, 0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1def585c2341f882c62f9c9e45f9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.24350759643606307, max=2.435075964360631, step=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.515700101852417 seconds to process\n"
     ]
    }
   ],
   "source": [
    "img = np.load('kinect_data/116.npy')\n",
    "output = get_obstacles_with_plane(img, num_planes = 10, \n",
    "                                  num_points = 5, \n",
    "                                  dist_thresh = 0.1, \n",
    "                                  visualize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The Windows bytes API has been deprecated, use Unicode filenames instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinect_data/0.npy\n",
      "Frame took 0.05896353721618652 seconds to process\n",
      "kinect_data/1.npy\n",
      "Frame took 0.05694460868835449 seconds to process\n",
      "kinect_data/10.npy\n",
      "Frame took 0.058947086334228516 seconds to process\n",
      "kinect_data/100.npy\n",
      "Frame took 0.06795191764831543 seconds to process\n",
      "kinect_data/101.npy\n",
      "Frame took 0.06397509574890137 seconds to process\n",
      "kinect_data/102.npy\n",
      "Frame took 0.06897807121276855 seconds to process\n",
      "kinect_data/103.npy\n",
      "Frame took 0.055953264236450195 seconds to process\n",
      "kinect_data/104.npy\n",
      "Frame took 0.07095909118652344 seconds to process\n",
      "kinect_data/105.npy\n",
      "Frame took 0.08093523979187012 seconds to process\n",
      "kinect_data/106.npy\n",
      "Frame took 0.06496047973632812 seconds to process\n",
      "kinect_data/107.npy\n",
      "Frame took 0.06596088409423828 seconds to process\n",
      "kinect_data/108.npy\n",
      "Frame took 0.06496262550354004 seconds to process\n",
      "kinect_data/109.npy\n",
      "Frame took 0.06296277046203613 seconds to process\n",
      "kinect_data/11.npy\n",
      "Frame took 0.10893535614013672 seconds to process\n",
      "kinect_data/110.npy\n",
      "Frame took 0.06696081161499023 seconds to process\n",
      "kinect_data/111.npy\n",
      "Frame took 0.06097984313964844 seconds to process\n",
      "kinect_data/112.npy\n",
      "Frame took 0.05494952201843262 seconds to process\n",
      "kinect_data/113.npy\n",
      "Frame took 0.05896425247192383 seconds to process\n",
      "kinect_data/114.npy\n",
      "Frame took 0.08794736862182617 seconds to process\n",
      "kinect_data/115.npy\n",
      "Frame took 0.06198000907897949 seconds to process\n",
      "kinect_data/116.npy\n",
      "Frame took 0.05496692657470703 seconds to process\n",
      "kinect_data/117.npy\n",
      "Frame took 0.06396031379699707 seconds to process\n",
      "kinect_data/118.npy\n",
      "Frame took 0.06596112251281738 seconds to process\n",
      "kinect_data/119.npy\n",
      "Frame took 0.06495928764343262 seconds to process\n",
      "kinect_data/12.npy\n",
      "Frame took 0.05596470832824707 seconds to process\n",
      "kinect_data/120.npy\n",
      "Frame took 0.06796050071716309 seconds to process\n",
      "kinect_data/121.npy\n",
      "Frame took 0.06696105003356934 seconds to process\n",
      "kinect_data/122.npy\n",
      "Frame took 0.06296300888061523 seconds to process\n",
      "kinect_data/123.npy\n",
      "Frame took 0.05996227264404297 seconds to process\n",
      "kinect_data/124.npy\n",
      "Frame took 0.055983543395996094 seconds to process\n",
      "kinect_data/125.npy\n",
      "Frame took 0.06095623970031738 seconds to process\n",
      "kinect_data/126.npy\n",
      "Frame took 0.05996513366699219 seconds to process\n",
      "kinect_data/127.npy\n",
      "Frame took 0.06294465065002441 seconds to process\n",
      "kinect_data/128.npy\n",
      "Frame took 0.07195210456848145 seconds to process\n",
      "kinect_data/129.npy\n",
      "Frame took 0.05896282196044922 seconds to process\n",
      "kinect_data/13.npy\n",
      "Frame took 0.06995964050292969 seconds to process\n",
      "kinect_data/130.npy\n",
      "Frame took 0.05996513366699219 seconds to process\n",
      "kinect_data/131.npy\n",
      "Frame took 0.052968740463256836 seconds to process\n",
      "kinect_data/132.npy\n",
      "Frame took 0.06294536590576172 seconds to process\n",
      "kinect_data/133.npy\n",
      "Frame took 0.06296038627624512 seconds to process\n",
      "kinect_data/134.npy\n",
      "Frame took 0.06296205520629883 seconds to process\n",
      "kinect_data/135.npy\n",
      "Frame took 0.06496143341064453 seconds to process\n",
      "kinect_data/136.npy\n",
      "Frame took 0.06696105003356934 seconds to process\n",
      "kinect_data/137.npy\n",
      "Frame took 0.05898284912109375 seconds to process\n",
      "kinect_data/138.npy\n",
      "Frame took 0.05496621131896973 seconds to process\n",
      "kinect_data/139.npy\n",
      "Frame took 0.052971601486206055 seconds to process\n",
      "kinect_data/14.npy\n",
      "Frame took 0.055965423583984375 seconds to process\n",
      "kinect_data/140.npy\n",
      "Frame took 0.061962127685546875 seconds to process\n",
      "kinect_data/141.npy\n",
      "Frame took 0.12692689895629883 seconds to process\n",
      "kinect_data/142.npy\n",
      "Frame took 0.05496621131896973 seconds to process\n",
      "kinect_data/143.npy\n",
      "Frame took 0.05296802520751953 seconds to process\n",
      "kinect_data/144.npy\n",
      "Frame took 0.054967641830444336 seconds to process\n",
      "kinect_data/145.npy\n",
      "Frame took 0.05996441841125488 seconds to process\n",
      "kinect_data/146.npy\n",
      "Frame took 0.056966304779052734 seconds to process\n",
      "kinect_data/147.npy\n",
      "Frame took 0.054967403411865234 seconds to process\n",
      "kinect_data/148.npy\n",
      "Frame took 0.052948713302612305 seconds to process\n",
      "kinect_data/149.npy\n",
      "Frame took 0.06993746757507324 seconds to process\n",
      "kinect_data/15.npy\n",
      "Frame took 0.05498385429382324 seconds to process\n",
      "kinect_data/150.npy\n",
      "Frame took 0.06795954704284668 seconds to process\n",
      "kinect_data/151.npy\n",
      "Frame took 0.06894969940185547 seconds to process\n",
      "kinect_data/152.npy\n",
      "Frame took 0.05796623229980469 seconds to process\n",
      "kinect_data/153.npy\n",
      "Frame took 0.06395792961120605 seconds to process\n",
      "kinect_data/154.npy\n",
      "Frame took 0.06595897674560547 seconds to process\n",
      "kinect_data/155.npy\n",
      "Frame took 0.05594825744628906 seconds to process\n",
      "kinect_data/156.npy\n",
      "Frame took 0.05994558334350586 seconds to process\n",
      "kinect_data/157.npy\n",
      "Frame took 0.06496047973632812 seconds to process\n",
      "kinect_data/158.npy\n",
      "Frame took 0.055950164794921875 seconds to process\n",
      "kinect_data/159.npy\n",
      "Frame took 0.058959245681762695 seconds to process\n",
      "kinect_data/16.npy\n",
      "Frame took 0.055948495864868164 seconds to process\n",
      "kinect_data/160.npy\n",
      "Frame took 0.06296253204345703 seconds to process\n",
      "kinect_data/161.npy\n",
      "Frame took 0.06296110153198242 seconds to process\n",
      "kinect_data/162.npy\n",
      "Frame took 0.06497716903686523 seconds to process\n",
      "kinect_data/163.npy\n",
      "Frame took 0.05994701385498047 seconds to process\n",
      "kinect_data/164.npy\n",
      "Frame took 0.06397485733032227 seconds to process\n",
      "kinect_data/165.npy\n",
      "Frame took 0.0629572868347168 seconds to process\n",
      "kinect_data/166.npy\n",
      "Frame took 0.06196093559265137 seconds to process\n",
      "kinect_data/167.npy\n",
      "Frame took 0.05896306037902832 seconds to process\n",
      "kinect_data/168.npy\n",
      "Frame took 0.0609743595123291 seconds to process\n",
      "kinect_data/169.npy\n",
      "Frame took 0.07297277450561523 seconds to process\n",
      "kinect_data/17.npy\n",
      "Frame took 0.058942317962646484 seconds to process\n",
      "kinect_data/170.npy\n",
      "Frame took 0.05395030975341797 seconds to process\n",
      "kinect_data/171.npy\n",
      "Frame took 0.061957597732543945 seconds to process\n",
      "kinect_data/172.npy\n",
      "Frame took 0.05296635627746582 seconds to process\n",
      "kinect_data/173.npy\n",
      "Frame took 0.06096482276916504 seconds to process\n",
      "kinect_data/174.npy\n",
      "Frame took 0.05995893478393555 seconds to process\n",
      "kinect_data/175.npy\n",
      "Frame took 0.06498026847839355 seconds to process\n",
      "kinect_data/176.npy\n",
      "Frame took 0.058963775634765625 seconds to process\n",
      "kinect_data/177.npy\n",
      "Frame took 0.055967092514038086 seconds to process\n",
      "kinect_data/178.npy\n",
      "Frame took 0.05396676063537598 seconds to process\n",
      "kinect_data/179.npy\n",
      "Frame took 0.06196284294128418 seconds to process\n",
      "kinect_data/18.npy\n",
      "Frame took 0.05395245552062988 seconds to process\n",
      "kinect_data/180.npy\n",
      "Frame took 0.07097053527832031 seconds to process\n",
      "kinect_data/181.npy\n",
      "Frame took 0.05894613265991211 seconds to process\n",
      "kinect_data/182.npy\n",
      "Frame took 0.06294727325439453 seconds to process\n",
      "kinect_data/183.npy\n",
      "Frame took 0.05997872352600098 seconds to process\n",
      "kinect_data/184.npy\n",
      "Frame took 0.06498026847839355 seconds to process\n",
      "kinect_data/185.npy\n",
      "Frame took 0.05996561050415039 seconds to process\n",
      "kinect_data/186.npy\n",
      "Frame took 0.10094022750854492 seconds to process\n",
      "kinect_data/187.npy\n",
      "Frame took 0.05996394157409668 seconds to process\n",
      "kinect_data/188.npy\n",
      "Frame took 0.057965755462646484 seconds to process\n",
      "kinect_data/189.npy\n",
      "Frame took 0.05896329879760742 seconds to process\n",
      "kinect_data/19.npy\n",
      "Frame took 0.05698251724243164 seconds to process\n",
      "kinect_data/190.npy\n",
      "Frame took 0.06395983695983887 seconds to process\n",
      "kinect_data/191.npy\n",
      "Frame took 0.06297636032104492 seconds to process\n",
      "kinect_data/192.npy\n",
      "Frame took 0.05996060371398926 seconds to process\n",
      "kinect_data/193.npy\n",
      "Frame took 0.06297659873962402 seconds to process\n",
      "kinect_data/194.npy\n",
      "Frame took 0.05396842956542969 seconds to process\n",
      "kinect_data/195.npy\n",
      "Frame took 0.05596518516540527 seconds to process\n",
      "kinect_data/196.npy\n",
      "Frame took 0.060962677001953125 seconds to process\n",
      "kinect_data/197.npy\n",
      "Frame took 0.05394935607910156 seconds to process\n",
      "kinect_data/198.npy\n",
      "Frame took 0.06695866584777832 seconds to process\n",
      "kinect_data/199.npy\n",
      "Frame took 0.05995965003967285 seconds to process\n",
      "kinect_data/2.npy\n",
      "Frame took 0.0559537410736084 seconds to process\n",
      "kinect_data/20.npy\n",
      "Frame took 0.055985212326049805 seconds to process\n",
      "kinect_data/200.npy\n",
      "Frame took 0.061945438385009766 seconds to process\n",
      "kinect_data/201.npy\n",
      "Frame took 0.06196236610412598 seconds to process\n",
      "kinect_data/202.npy\n",
      "Frame took 0.06896018981933594 seconds to process\n",
      "kinect_data/203.npy\n",
      "Frame took 0.05896615982055664 seconds to process\n",
      "kinect_data/204.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame took 0.06695914268493652 seconds to process\n",
      "kinect_data/205.npy\n",
      "Frame took 0.05896615982055664 seconds to process\n",
      "kinect_data/206.npy\n",
      "Frame took 0.07695174217224121 seconds to process\n",
      "kinect_data/207.npy\n",
      "Frame took 0.05496668815612793 seconds to process\n",
      "kinect_data/208.npy\n",
      "Frame took 0.058965444564819336 seconds to process\n",
      "kinect_data/209.npy\n",
      "Frame took 0.06796026229858398 seconds to process\n",
      "kinect_data/21.npy\n",
      "Frame took 0.06994056701660156 seconds to process\n",
      "kinect_data/210.npy\n",
      "Frame took 0.059966087341308594 seconds to process\n",
      "kinect_data/211.npy\n",
      "Frame took 0.054967403411865234 seconds to process\n",
      "kinect_data/212.npy\n",
      "Frame took 0.056948184967041016 seconds to process\n",
      "kinect_data/213.npy\n",
      "Frame took 0.05496788024902344 seconds to process\n",
      "kinect_data/214.npy\n",
      "Frame took 0.05796647071838379 seconds to process\n",
      "kinect_data/215.npy\n",
      "Frame took 0.055950164794921875 seconds to process\n",
      "kinect_data/216.npy\n",
      "Frame took 0.057965755462646484 seconds to process\n",
      "kinect_data/217.npy\n",
      "Frame took 0.05694699287414551 seconds to process\n",
      "kinect_data/218.npy\n",
      "Frame took 0.058966875076293945 seconds to process\n",
      "kinect_data/219.npy\n",
      "Frame took 0.05497145652770996 seconds to process\n",
      "kinect_data/22.npy\n",
      "Frame took 0.05795097351074219 seconds to process\n",
      "kinect_data/220.npy\n",
      "Frame took 0.05596756935119629 seconds to process\n",
      "kinect_data/221.npy\n",
      "Frame took 0.06995701789855957 seconds to process\n",
      "kinect_data/222.npy\n",
      "Frame took 0.056949615478515625 seconds to process\n",
      "kinect_data/223.npy\n",
      "Frame took 0.06096339225769043 seconds to process\n",
      "kinect_data/224.npy\n",
      "Frame took 0.05497026443481445 seconds to process\n",
      "kinect_data/225.npy\n",
      "Frame took 0.05794858932495117 seconds to process\n",
      "kinect_data/226.npy\n",
      "Frame took 0.11893153190612793 seconds to process\n",
      "kinect_data/227.npy\n",
      "Frame took 0.055948495864868164 seconds to process\n",
      "kinect_data/228.npy\n",
      "Frame took 0.055965423583984375 seconds to process\n",
      "kinect_data/229.npy\n",
      "Frame took 0.07494187355041504 seconds to process\n",
      "kinect_data/23.npy\n",
      "Frame took 0.05995345115661621 seconds to process\n",
      "kinect_data/24.npy\n",
      "Frame took 0.06795883178710938 seconds to process\n",
      "kinect_data/25.npy\n",
      "Frame took 0.06195330619812012 seconds to process\n",
      "kinect_data/26.npy\n",
      "Frame took 0.06695842742919922 seconds to process\n",
      "kinect_data/27.npy\n",
      "Frame took 0.06795358657836914 seconds to process\n",
      "kinect_data/28.npy\n",
      "Frame took 0.06096172332763672 seconds to process\n",
      "kinect_data/29.npy\n",
      "Frame took 0.06594157218933105 seconds to process\n",
      "kinect_data/3.npy\n",
      "Frame took 0.0599820613861084 seconds to process\n",
      "kinect_data/30.npy\n",
      "Frame took 0.05594992637634277 seconds to process\n",
      "kinect_data/31.npy\n",
      "Frame took 0.05696392059326172 seconds to process\n",
      "kinect_data/32.npy\n",
      "Frame took 0.06594228744506836 seconds to process\n",
      "kinect_data/33.npy\n",
      "Frame took 0.06595897674560547 seconds to process\n",
      "kinect_data/34.npy\n",
      "Frame took 0.06494379043579102 seconds to process\n",
      "kinect_data/35.npy\n",
      "Frame took 0.06197404861450195 seconds to process\n",
      "kinect_data/36.npy\n",
      "Frame took 0.06894183158874512 seconds to process\n",
      "kinect_data/37.npy\n",
      "Frame took 0.06697702407836914 seconds to process\n",
      "kinect_data/38.npy\n",
      "Frame took 0.05894660949707031 seconds to process\n",
      "kinect_data/39.npy\n",
      "Frame took 0.07995319366455078 seconds to process\n",
      "kinect_data/4.npy\n",
      "Frame took 0.12092971801757812 seconds to process\n",
      "kinect_data/40.npy\n",
      "Frame took 0.07095527648925781 seconds to process\n",
      "kinect_data/41.npy\n",
      "Frame took 0.0739750862121582 seconds to process\n",
      "kinect_data/42.npy\n",
      "Frame took 0.056946516036987305 seconds to process\n",
      "kinect_data/43.npy\n",
      "Frame took 0.0699605941772461 seconds to process\n",
      "kinect_data/44.npy\n",
      "Frame took 0.06895852088928223 seconds to process\n",
      "kinect_data/45.npy\n",
      "Frame took 0.0609593391418457 seconds to process\n",
      "kinect_data/46.npy\n",
      "Frame took 0.05896568298339844 seconds to process\n",
      "kinect_data/47.npy\n",
      "Frame took 0.06196713447570801 seconds to process\n",
      "kinect_data/48.npy\n",
      "Frame took 0.05796694755554199 seconds to process\n",
      "kinect_data/49.npy\n",
      "Frame took 0.05698227882385254 seconds to process\n",
      "kinect_data/5.npy\n",
      "Frame took 0.0599675178527832 seconds to process\n",
      "kinect_data/50.npy\n",
      "Frame took 0.0709538459777832 seconds to process\n",
      "kinect_data/51.npy\n",
      "Frame took 0.06295132637023926 seconds to process\n",
      "kinect_data/52.npy\n",
      "Frame took 0.0669407844543457 seconds to process\n",
      "kinect_data/53.npy\n",
      "Frame took 0.07094383239746094 seconds to process\n",
      "kinect_data/54.npy\n",
      "Frame took 0.07295489311218262 seconds to process\n",
      "kinect_data/55.npy\n",
      "Frame took 0.06695938110351562 seconds to process\n",
      "kinect_data/56.npy\n",
      "Frame took 0.07195210456848145 seconds to process\n",
      "kinect_data/57.npy\n",
      "Frame took 0.07395577430725098 seconds to process\n",
      "kinect_data/58.npy\n",
      "Frame took 0.06897306442260742 seconds to process\n",
      "kinect_data/59.npy\n",
      "Frame took 0.06595587730407715 seconds to process\n",
      "kinect_data/6.npy\n",
      "Frame took 0.0829315185546875 seconds to process\n",
      "kinect_data/60.npy\n",
      "Frame took 0.06395840644836426 seconds to process\n",
      "kinect_data/61.npy\n",
      "Frame took 0.07094025611877441 seconds to process\n",
      "kinect_data/62.npy\n",
      "Frame took 0.054965972900390625 seconds to process\n",
      "kinect_data/63.npy\n",
      "Frame took 0.07993435859680176 seconds to process\n",
      "kinect_data/64.npy\n",
      "Frame took 0.07196998596191406 seconds to process\n",
      "kinect_data/65.npy\n",
      "Frame took 0.06794214248657227 seconds to process\n",
      "kinect_data/66.npy\n",
      "Frame took 0.074951171875 seconds to process\n",
      "kinect_data/67.npy\n",
      "Frame took 0.07992720603942871 seconds to process\n",
      "kinect_data/68.npy\n",
      "Frame took 0.05696225166320801 seconds to process\n",
      "kinect_data/69.npy\n",
      "Frame took 0.0809636116027832 seconds to process\n",
      "kinect_data/7.npy\n",
      "Frame took 0.056962013244628906 seconds to process\n",
      "kinect_data/70.npy\n",
      "Frame took 0.07095575332641602 seconds to process\n",
      "kinect_data/71.npy\n",
      "Frame took 0.06995844841003418 seconds to process\n",
      "kinect_data/72.npy\n",
      "Frame took 0.0609433650970459 seconds to process\n",
      "kinect_data/73.npy\n",
      "Frame took 0.060944318771362305 seconds to process\n",
      "kinect_data/74.npy\n",
      "Frame took 0.05894875526428223 seconds to process\n",
      "kinect_data/75.npy\n",
      "Frame took 0.055948734283447266 seconds to process\n",
      "kinect_data/76.npy\n",
      "Frame took 0.10693883895874023 seconds to process\n",
      "kinect_data/77.npy\n",
      "Frame took 0.07195806503295898 seconds to process\n",
      "kinect_data/78.npy\n",
      "Frame took 0.05595898628234863 seconds to process\n",
      "kinect_data/79.npy\n",
      "Frame took 0.055948734283447266 seconds to process\n",
      "kinect_data/8.npy\n",
      "Frame took 0.06596112251281738 seconds to process\n",
      "kinect_data/80.npy\n",
      "Frame took 0.06596016883850098 seconds to process\n",
      "kinect_data/81.npy\n",
      "Frame took 0.06895828247070312 seconds to process\n",
      "kinect_data/82.npy\n",
      "Frame took 0.057969093322753906 seconds to process\n",
      "kinect_data/83.npy\n",
      "Frame took 0.0699615478515625 seconds to process\n",
      "kinect_data/84.npy\n",
      "Frame took 0.057958364486694336 seconds to process\n",
      "kinect_data/85.npy\n",
      "Frame took 0.06694316864013672 seconds to process\n",
      "kinect_data/86.npy\n",
      "Frame took 0.07693123817443848 seconds to process\n",
      "kinect_data/87.npy\n",
      "Frame took 0.07093954086303711 seconds to process\n",
      "kinect_data/88.npy\n",
      "Frame took 0.07697367668151855 seconds to process\n",
      "kinect_data/89.npy\n",
      "Frame took 0.1249086856842041 seconds to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jumpr_000\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\jumpr_000\\AppData\\Roaming\\Python\\Python35\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\jumpr_000\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:105: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinect_data/9.npy\n",
      "Frame took 0.05696606636047363 seconds to process\n",
      "kinect_data/90.npy\n",
      "Frame took 0.07095694541931152 seconds to process\n",
      "kinect_data/91.npy\n",
      "Frame took 0.07795262336730957 seconds to process\n",
      "kinect_data/92.npy\n",
      "Frame took 0.06594300270080566 seconds to process\n",
      "kinect_data/93.npy\n",
      "Frame took 0.06894326210021973 seconds to process\n",
      "kinect_data/94.npy\n",
      "Frame took 0.07195687294006348 seconds to process\n",
      "kinect_data/95.npy\n",
      "Frame took 0.10293984413146973 seconds to process\n",
      "kinect_data/96.npy\n",
      "Frame took 0.06096339225769043 seconds to process\n",
      "kinect_data/97.npy\n",
      "Frame took 0.0649564266204834 seconds to process\n",
      "kinect_data/98.npy\n",
      "Frame took 0.07895469665527344 seconds to process\n",
      "kinect_data/99.npy\n",
      "Frame took 0.06296133995056152 seconds to process\n"
     ]
    }
   ],
   "source": [
    "frames_dir = 'kinect_data/'\n",
    "directory = os.fsencode(frames_dir)\n",
    "frame_i = 0\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\".npy\"):\n",
    "        file_path = frames_dir + filename\n",
    "        print(file_path)\n",
    "        img = np.load(file_path)\n",
    "        try:\n",
    "            output = get_obstacles_with_plane(img, num_planes = 10, \n",
    "                                  num_points = 5, \n",
    "                                  dist_thresh = 0.1, \n",
    "                                  visualize = False)\n",
    "            cv2.imwrite(str(frame_i) + '.png', output)\n",
    "            frame_i += 1\n",
    "        except:\n",
    "            print(\"Could not find obstacles\")\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
